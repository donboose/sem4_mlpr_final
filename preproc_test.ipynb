{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d146d37d-e770-48b6-be59-72870148a78f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:46:38.101575Z",
     "iopub.status.busy": "2025-05-14T11:46:38.101397Z",
     "iopub.status.idle": "2025-05-14T11:46:38.691624Z",
     "shell.execute_reply": "2025-05-14T11:46:38.691221Z",
     "shell.execute_reply.started": "2025-05-14T11:46:38.101558Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import glob\n",
    "\n",
    "import h5py\n",
    "import gc\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "318c9b51-ee6b-4405-b470-241e39ea0b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T21:41:44.059730Z",
     "iopub.status.busy": "2025-05-07T21:41:44.059269Z",
     "iopub.status.idle": "2025-05-07T21:41:44.064785Z",
     "shell.execute_reply": "2025-05-07T21:41:44.064350Z",
     "shell.execute_reply.started": "2025-05-07T21:41:44.059702Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_target_lengths(split_df, percentile=95):\n",
    "    \"\"\"Calculate target temporal lengths for each feature.\"\"\"\n",
    "    target_lengths = {}\n",
    "    \n",
    "    # First pass to calculate lengths\n",
    "    print(\"Calculating target temporal lengths...\")\n",
    "    for _, row in split_df.iterrows():\n",
    "        p_id = row[\"Participant_ID\"]\n",
    "        features_dir = f\"../dataset/edaicwoz_participant/{p_id}_P/{p_id}_P/features\"\n",
    "        \n",
    "        # Load one sample of each feature type\n",
    "        paths = {\n",
    "            'audio_vgg16': f\"{p_id}_vgg16.csv\",\n",
    "            'audio_densenet': f\"{p_id}_densenet201.csv\",\n",
    "            'visual_resnet': f\"{p_id}_CNN_ResNet.mat\",\n",
    "            'visual_vgg': f\"{p_id}_CNN_VGG.mat\",\n",
    "            'audio_mfcc': f\"{p_id}_OpenSMILE2.3.0_mfcc.csv\",\n",
    "            'audio_egemaps': f\"{p_id}_OpenSMILE2.3.0_egemaps.csv\",\n",
    "            'visual_of': f\"{p_id}_OpenFace2.1.0_Pose_gaze_AUs.csv\"\n",
    "        }\n",
    "        \n",
    "        for feat_name, path in paths.items():\n",
    "            full_path = os.path.join(features_dir, path)\n",
    "            if feat_name.endswith('.mat'):\n",
    "                data = loadmat(full_path)['feature']\n",
    "            else:\n",
    "                data = pd.read_csv(full_path).iloc[:, 1:].values\n",
    "                \n",
    "            current_len = data.shape[0]\n",
    "            if feat_name not in target_lengths:\n",
    "                target_lengths[feat_name] = []\n",
    "            target_lengths[feat_name].append(current_len)\n",
    "    \n",
    "    # Calculate percentile-based target lengths\n",
    "    return {\n",
    "        feat: int(np.percentile(lens, percentile))\n",
    "        for feat, lens in target_lengths.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a595585-bb0c-4727-bff1-221718a8bbe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T21:42:46.721125Z",
     "iopub.status.busy": "2025-05-07T21:42:46.720872Z",
     "iopub.status.idle": "2025-05-07T21:42:46.725010Z",
     "shell.execute_reply": "2025-05-07T21:42:46.724674Z",
     "shell.execute_reply.started": "2025-05-07T21:42:46.721108Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(features, pca_models=None, scalers=None, target_lengths=None):\n",
    "    if pca_models is None:\n",
    "        pca_models = {}\n",
    "    if scalers is None:\n",
    "        scalers = {}\n",
    "    if target_lengths is None:\n",
    "        target_lengths = {}\n",
    "\n",
    "    processed = {}\n",
    "    \n",
    "    # Temporal standardization first\n",
    "    for feat_name in features:\n",
    "        feat_data = features[feat_name]\n",
    "        \n",
    "        # Pad/truncate temporal dimension\n",
    "        if feat_name in target_lengths:\n",
    "            current_len = feat_data.shape[0]\n",
    "            target_len = target_lengths[feat_name]\n",
    "            \n",
    "            if current_len >= target_len:\n",
    "                # Truncate\n",
    "                feat_data = feat_data[:target_len]\n",
    "            else:\n",
    "                # Pad with zeros\n",
    "                pad_shape = (target_len - current_len,) + feat_data.shape[1:]\n",
    "                feat_data = np.vstack([feat_data, np.zeros(pad_shape)])\n",
    "        \n",
    "        # Apply scaling\n",
    "        if feat_name not in scalers:\n",
    "            scalers[feat_name] = RobustScaler()\n",
    "            scalers[feat_name].fit(feat_data)\n",
    "        scaled = scalers[feat_name].transform(feat_data)\n",
    "\n",
    "        # Apply PCA if needed\n",
    "        if feat_name in pca_models:\n",
    "            if pca_models[feat_name] is None:\n",
    "                # Initialize PCA if first time\n",
    "                pca_models[feat_name] = PCA(n_components=0.95)\n",
    "                pca_models[feat_name].fit(scaled)\n",
    "            reduced = pca_models[feat_name].transform(scaled)\n",
    "            processed[feat_name] = reduced\n",
    "        else:\n",
    "            processed[feat_name] = scaled\n",
    "\n",
    "    return processed, pca_models, scalers, target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb9f74a2-3328-424c-86c5-5589a9539d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T21:44:20.472311Z",
     "iopub.status.busy": "2025-05-07T21:44:20.472054Z",
     "iopub.status.idle": "2025-05-07T21:44:20.476273Z",
     "shell.execute_reply": "2025-05-07T21:44:20.475875Z",
     "shell.execute_reply.started": "2025-05-07T21:44:20.472285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_to_h5file(data_dict, split_name):\n",
    "    filename = f\"{split_name}_processed.h5\"\n",
    "    \n",
    "    with h5py.File(filename, 'a') as hf:\n",
    "        for pid, features in data_dict.items():\n",
    "            if str(pid) in hf:\n",
    "                del hf[str(pid)]\n",
    "                \n",
    "            grp = hf.create_group(str(pid))\n",
    "            for feat_name, feat_data in features.items():\n",
    "                # Enforce float32 and chunked storage\n",
    "                grp.create_dataset(feat_name, \n",
    "                                 data=feat_data.astype('float32'),\n",
    "                                 chunks=True,\n",
    "                                 maxshape=(None,) + feat_data.shape[1:],\n",
    "                                 compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb742492-5b96-4fd8-9c8d-7710ccc40c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T21:44:21.365811Z",
     "iopub.status.busy": "2025-05-07T21:44:21.365615Z",
     "iopub.status.idle": "2025-05-07T21:44:21.371188Z",
     "shell.execute_reply": "2025-05-07T21:44:21.370795Z",
     "shell.execute_reply.started": "2025-05-07T21:44:21.365795Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(split=\"train\"):\n",
    "    full_path = \"../dataset/edaicwoz_labels/\" + split + \"_split.csv\"\n",
    "    split_file_df = pd.read_csv(full_path)\n",
    "    \n",
    "    if \"train\" in split:\n",
    "        target_lengths = calculate_target_lengths(split_file_df, percentile=95)\n",
    "    else:\n",
    "        # For dev/test, use training target lengths (needs to be loaded from disk)\n",
    "        target_lengths = load_target_lengths()  # Implement this to load from file\n",
    "        \n",
    "    pca_models = defaultdict(lambda: None)\n",
    "    scalers = {}\n",
    "    \n",
    "    for idx, row in enumerate(split_file_df.iterrows()):        \n",
    "        p_id = row[1][\"Participant_ID\"]\n",
    "        features_dir = f\"../dataset/edaicwoz_participant/{p_id}_P/{p_id}_P/features\"\n",
    "        aggregated_features_for_participant = []\n",
    "        \n",
    "        # audio\n",
    "        boaw_egemaps_path = os.path.join(features_dir, f\"{p_id}_BoAW_openSMILE_2.3.0_eGeMAPS.csv\") # 1\n",
    "        boaw_mfcc_path = os.path.join(features_dir, f\"{p_id}_BoAW_openSMILE_2.3.0_MFCC.csv\") # 2\n",
    "        egemaps_path = os.path.join(features_dir, f\"{p_id}_OpenSMILE2.3.0_egemaps.csv\") # 8\n",
    "        mfcc_path = os.path.join(features_dir, f\"{p_id}_OpenSMILE2.3.0_mfcc.csv\") # 9\n",
    "        vgg16_path = os.path.join(features_dir, f\"{p_id}_vgg16.csv\") # 10\n",
    "        densenet_path = os.path.join(features_dir, f\"{p_id}_densenet201.csv\") # 6\n",
    "        \n",
    "        # visual\n",
    "        bovw_openface_pg_path = os.path.join(features_dir, f\"{p_id}_BoVW_openFace_2.1.0_Pose_Gaze_AUs.csv\") # 3\n",
    "        openface_pg_path = os.path.join(features_dir, f\"{p_id}_OpenFace2.1.0_Pose_gaze_AUs.csv\") # 7\n",
    "        resnet_path = os.path.join(features_dir, f\"{p_id}_CNN_ResNet.mat\") # 4\n",
    "        vgg_path = os.path.join(features_dir, f\"{p_id}_CNN_VGG.mat\") # 5\n",
    "\n",
    "        ptsd_binary = row[1][\"PCL-C (PTSD)\"]\n",
    "        \n",
    "        features = {\n",
    "            # \"audio_boaw_ege\": pd.read_csv(boaw_egemaps_path, header=None).iloc[:, 1:].values,\n",
    "            # \"audio_boaw_mfcc\": pd.read_csv(boaw_mfcc_path, header=None).iloc[:, 1:].values,\n",
    "            \"audio_egemaps\": pd.read_csv(egemaps_path, sep=\";\").iloc[:, 1:].values,\n",
    "            \"audio_mfcc\": pd.read_csv(mfcc_path, sep=\";\").iloc[:, 1:].values,\n",
    "            \"audio_vgg16\": pd.read_csv(vgg16_path).iloc[:, 1:].values,\n",
    "            \"audio_densenet\": pd.read_csv(densenet_path).iloc[:, 1:].values,\n",
    "            \"visual_bovw_of\": pd.read_csv(bovw_openface_pg_path, header=None).iloc[:, 1:].select_dtypes(include=np.number).values,\n",
    "            \"visual_of\": pd.read_csv(openface_pg_path).select_dtypes(include=np.number) .values,\n",
    "            \"visual_resnet\": loadmat(resnet_path)[\"feature\"],\n",
    "            \"visual_vgg\": loadmat(vgg_path)['feature'],\n",
    "        }\n",
    "        \n",
    "        processed, pca_models, scalers, _ = preprocess_data(\n",
    "            features, \n",
    "            pca_models, \n",
    "            scalers,\n",
    "            target_lengths\n",
    "        )\n",
    "        \n",
    "        save_to_h5file({p_id: processed}, split_base)\n",
    "        \n",
    "        del features, processed\n",
    "        gc.collect() \n",
    "\n",
    "        print(f\".... {p_id} done [processed and saved] ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "580c0d17-b28e-4e17-af1c-86719e849c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T21:44:22.790204Z",
     "iopub.status.busy": "2025-05-07T21:44:22.790027Z",
     "iopub.status.idle": "2025-05-07T21:44:23.242981Z",
     "shell.execute_reply": "2025-05-07T21:44:23.242397Z",
     "shell.execute_reply.started": "2025-05-07T21:44:22.790190Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating target temporal lengths...\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc0 in position 133: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m      3\u001b[0m split_file_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(full_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m split:\n\u001b[0;32m----> 6\u001b[0m     target_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_target_lengths\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_file_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m95\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# For dev/test, use training target lengths (needs to be loaded from disk)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     target_lengths \u001b[38;5;241m=\u001b[39m load_target_lengths()  \u001b[38;5;66;03m# Implement this to load from file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m, in \u001b[0;36mcalculate_target_lengths\u001b[0;34m(split_df, percentile)\u001b[0m\n\u001b[1;32m     25\u001b[0m     data \u001b[38;5;241m=\u001b[39m loadmat(full_path)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     29\u001b[0m current_len \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feat_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m target_lengths:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc0 in position 133: invalid start byte"
     ]
    }
   ],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d92ccaed-a9f2-49da-8bf5-1edd598c6525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T21:37:42.941040Z",
     "iopub.status.busy": "2025-05-07T21:37:42.940819Z",
     "iopub.status.idle": "2025-05-07T21:37:42.946222Z",
     "shell.execute_reply": "2025-05-07T21:37:42.945879Z",
     "shell.execute_reply.started": "2025-05-07T21:37:42.941019Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 features: \n",
      "audio_vgg16: (758, 512)\n",
      "audio_densenet: (758, 512)\n",
      "visual_resnet: (22766, 512)\n",
      "visual_vgg: (22766, 512)\n",
      "audio_mfcc: (75878, 40)\n",
      "audio_egemaps: (75876, 24)\n",
      "visual_of: (22766, 53)\n",
      "303 features: \n",
      "audio_vgg16: (985, 512)\n",
      "audio_densenet: (985, 512)\n",
      "visual_resnet: (29565, 512)\n",
      "visual_vgg: (29565, 512)\n",
      "audio_mfcc: (98528, 40)\n",
      "audio_egemaps: (98526, 24)\n",
      "visual_of: (29565, 53)\n",
      "304 features: \n",
      "audio_vgg16: (788, 512)\n",
      "audio_densenet: (788, 512)\n",
      "visual_resnet: (23780, 512)\n",
      "visual_vgg: (23780, 512)\n",
      "audio_mfcc: (79258, 40)\n",
      "audio_egemaps: (79256, 24)\n",
      "visual_of: (23780, 53)\n",
      "305 features: \n",
      "audio_vgg16: (1704, 512)\n",
      "audio_densenet: (1704, 512)\n",
      "visual_resnet: (51122, 512)\n",
      "visual_vgg: (51122, 512)\n",
      "audio_mfcc: (170398, 40)\n",
      "audio_egemaps: (170396, 24)\n",
      "visual_of: (51122, 53)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../storage/transform/train_processed.h5', 'r') as hf:\n",
    "    for i in ['302', '303', '304', '305']:\n",
    "        print(f\"{i} features: \")\n",
    "        print(f\"audio_vgg16: {hf[i]['audio_vgg16'].shape}\")\n",
    "        print(f\"audio_densenet: {hf[i]['audio_densenet'].shape}\")\n",
    "        print(f\"visual_resnet: {hf[i]['visual_resnet'].shape}\")\n",
    "        print(f\"visual_vgg: {hf[i]['visual_vgg'].shape}\")\n",
    "        print(f\"audio_mfcc: {hf[i]['audio_mfcc'].shape}\")\n",
    "        print(f\"audio_egemaps: {hf[i]['audio_egemaps'].shape}\")\n",
    "        print(f\"visual_of: {hf[i]['visual_of'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f19c20a-c3f3-4da7-b149-a11a495cb696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:57:06.251449Z",
     "iopub.status.busy": "2025-05-14T11:57:06.251214Z",
     "iopub.status.idle": "2025-05-14T11:57:06.257021Z",
     "shell.execute_reply": "2025-05-14T11:57:06.256613Z",
     "shell.execute_reply.started": "2025-05-14T11:57:06.251432Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(split=\"train\"):\n",
    "    full_path = \"../dataset/edaicwoz_labels/\" + split + \"_split.csv\"\n",
    "    split_file_df = pd.read_csv(full_path)\n",
    "    \n",
    "    for idx, row in enumerate(split_file_df.iterrows()):        \n",
    "        p_id = row[1][\"Participant_ID\"]\n",
    "        features_dir = f\"../dataset/edaicwoz_participant/{p_id}_P/{p_id}_P/features\"\n",
    "        aggregated_features_for_participant = []\n",
    "        \n",
    "        # audio\n",
    "        boaw_egemaps_path = os.path.join(features_dir, f\"{p_id}_BoAW_openSMILE_2.3.0_eGeMAPS.csv\") # 1\n",
    "        boaw_mfcc_path = os.path.join(features_dir, f\"{p_id}_BoAW_openSMILE_2.3.0_MFCC.csv\") # 2\n",
    "        egemaps_path = os.path.join(features_dir, f\"{p_id}_OpenSMILE2.3.0_egemaps.csv\") # 8\n",
    "        mfcc_path = os.path.join(features_dir, f\"{p_id}_OpenSMILE2.3.0_mfcc.csv\") # 9\n",
    "        vgg16_path = os.path.join(features_dir, f\"{p_id}_vgg16.csv\") # 10\n",
    "        densenet_path = os.path.join(features_dir, f\"{p_id}_densenet201.csv\") # 6\n",
    "        \n",
    "        # visual\n",
    "        bovw_openface_pg_path = os.path.join(features_dir, f\"{p_id}_BoVW_openFace_2.1.0_Pose_Gaze_AUs.csv\") # 3\n",
    "        openface_pg_path = os.path.join(features_dir, f\"{p_id}_OpenFace2.1.0_Pose_gaze_AUs.csv\") # 7\n",
    "        resnet_path = os.path.join(features_dir, f\"{p_id}_CNN_ResNet.mat\") # 4\n",
    "        vgg_path = os.path.join(features_dir, f\"{p_id}_CNN_VGG.mat\") # 5\n",
    "\n",
    "        ptsd_binary = row[1][\"PCL-C (PTSD)\"]\n",
    "        \n",
    "        features = {\n",
    "            \"audio_boaw_ege\": pd.read_csv(boaw_egemaps_path, header=None).iloc[:, 2:].values,\n",
    "            \"audio_boaw_mfcc\": pd.read_csv(boaw_mfcc_path, header=None).iloc[:, 2:].values,\n",
    "            \"audio_egemaps\": pd.read_csv(egemaps_path, sep=\";\").iloc[:, 1:].values,\n",
    "            \"audio_mfcc\": pd.read_csv(mfcc_path, sep=\";\").iloc[:, 1:].values,\n",
    "            \"audio_vgg16\": pd.read_csv(vgg16_path).iloc[:, 2:].values,\n",
    "            \"audio_densenet\": pd.read_csv(densenet_path).iloc[:, 2:].values,\n",
    "            \"visual_bovw_of\": pd.read_csv(bovw_openface_pg_path, header=None).iloc[:, 2:].select_dtypes(include=np.number).values,\n",
    "            \"visual_of\": pd.read_csv(openface_pg_path).select_dtypes(include=np.number) .values,\n",
    "            \"visual_resnet\": loadmat(resnet_path)[\"feature\"],\n",
    "            \"visual_vgg\": loadmat(vgg_path)['feature'],\n",
    "        }\n",
    "        \n",
    "        print(p_id)\n",
    "        \n",
    "        print(f\"audio_egemaps: {features['audio_egemaps'].shape}\")\n",
    "        print(f\"audio_mfcc: {features['audio_mfcc'].shape}\")\n",
    "        print(f\"audio_vgg16: {features['audio_vgg16'].shape}\")\n",
    "        print(f\"audio_densenet: {features['audio_densenet'].shape}\")\n",
    "        print(f\"visual_bovw_of: {features['visual_bovw_of'].shape}\")\n",
    "        print(f\"visual_of: {features['visual_of'].shape}\")\n",
    "        print(f\"visual_resnet: {features['visual_resnet'].shape}\")\n",
    "        print(f\"visual_vgg: {features['visual_vgg'].shape}\")\n",
    "        \n",
    "        print(f\"\\ndesnsenet: {features['audio_densenet']}\")\n",
    "        print(f\"\\nvgg16: {features['audio_vgg16']}\")\n",
    "        print(f\"\\nvgg: {features['visual_vgg']}\")\n",
    "        \n",
    "        # print(f\"audio_boaw_ege: {features['audio_boaw_ege'].shape}\")\n",
    "        # print(f\"audio_boaw_mfcc: {features['audio_boaw_mfcc'].shape}\")\n",
    "        # print(f\"visual_bovw_of: {features['visual_bovw_of'].shape}\")\n",
    "        \n",
    "        del features\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d313dc-0ce3-4427-be3b-e5c8a44ef681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T11:57:06.616088Z",
     "iopub.status.busy": "2025-05-14T11:57:06.615908Z",
     "iopub.status.idle": "2025-05-14T11:57:09.423835Z",
     "shell.execute_reply": "2025-05-14T11:57:09.423338Z",
     "shell.execute_reply.started": "2025-05-14T11:57:06.616073Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n",
      "audio_egemaps: (75876, 24)\n",
      "audio_mfcc: (75878, 40)\n",
      "audio_vgg16: (758, 4096)\n",
      "audio_densenet: (758, 1920)\n",
      "visual_bovw_of: (7589, 100)\n",
      "visual_of: (22766, 53)\n",
      "visual_resnet: (22766, 2048)\n",
      "visual_vgg: (22766, 4096)\n",
      "\n",
      "desnsenet: [[4.13115500e-05 2.62318800e-04 1.19398500e-03 ... 2.32202140e-01\n",
      "  6.62418370e-01 9.13221800e-01]\n",
      " [4.20029320e-05 4.18474300e-04 8.80428900e-04 ... 1.06265634e-01\n",
      "  7.02257900e-01 6.60984800e-01]\n",
      " [3.20921600e-05 2.79641740e-04 4.78916070e-04 ... 1.27977520e-01\n",
      "  1.58896650e+00 7.55539500e-01]\n",
      " ...\n",
      " [5.21376240e-05 3.94868750e-04 6.91148700e-04 ... 1.32203280e-01\n",
      "  1.11729870e+00 4.82479960e-01]\n",
      " [2.53436600e-05 4.57050630e-04 1.03011260e-03 ... 2.56852100e-01\n",
      "  1.04215840e+00 1.11969670e+00]\n",
      " [4.05782500e-05 4.35246800e-04 7.67430230e-04 ... 5.02721850e-01\n",
      "  1.07464660e+00 3.51064830e-01]]\n",
      "\n",
      "vgg16: [[0.         0.         0.         ... 2.8741732  0.24951726 0.        ]\n",
      " [0.         0.         0.         ... 2.2591581  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.7599014  0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.7530968  0.45223337 0.        ]\n",
      " [0.         0.         0.         ... 0.8095958  1.0165393  0.8349095 ]\n",
      " [0.         0.         0.         ... 1.4619348  0.         0.35235804]]\n",
      "\n",
      "vgg: [[0.         0.01313809 0.         ... 0.         0.00074903 0.00929907]\n",
      " [0.         0.01302546 0.         ... 0.         0.0006439  0.00875858]\n",
      " [0.         0.01314303 0.         ... 0.         0.00071238 0.00889472]\n",
      " ...\n",
      " [0.         0.01250591 0.         ... 0.         0.00180607 0.0096295 ]\n",
      " [0.         0.01299693 0.         ... 0.         0.00190357 0.00974634]\n",
      " [0.         0.01313529 0.         ... 0.         0.00192012 0.00976977]]\n",
      "303\n",
      "audio_egemaps: (98526, 24)\n",
      "audio_mfcc: (98528, 40)\n",
      "audio_vgg16: (985, 4096)\n",
      "audio_densenet: (985, 1920)\n",
      "visual_bovw_of: (9855, 100)\n",
      "visual_of: (29565, 53)\n",
      "visual_resnet: (29565, 2048)\n",
      "visual_vgg: (29565, 4096)\n",
      "\n",
      "desnsenet: [[2.5866964e-05 3.6622584e-04 9.6422376e-04 ... 1.4856683e-01\n",
      "  8.1580330e-01 1.8258560e-01]\n",
      " [5.2007540e-05 2.8731496e-04 7.3312150e-04 ... 2.3484874e-01\n",
      "  7.9363350e-01 2.0376614e-01]\n",
      " [3.5258550e-05 2.0265038e-04 6.2312884e-04 ... 5.6666035e-02\n",
      "  7.4342880e-01 4.2549133e-01]\n",
      " ...\n",
      " [2.6676642e-05 4.2601100e-04 8.0434800e-04 ... 2.2025038e-01\n",
      "  7.6460170e-01 4.4562528e-01]\n",
      " [3.0528860e-05 3.9885930e-04 9.2647620e-04 ... 5.8257464e-02\n",
      "  9.7372484e-01 6.0443080e-01]\n",
      " [4.9821036e-05 4.2798067e-04 8.4968517e-04 ... 5.8730810e-02\n",
      "  8.3861290e-01 5.1981360e-01]]\n",
      "\n",
      "vgg16: [[0.         0.         0.         ... 0.75648963 0.         0.12478489]\n",
      " [0.         0.         0.         ... 1.052454   0.         0.        ]\n",
      " [0.         0.         0.         ... 1.3062935  0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.6371458  0.20213607 0.09920329]\n",
      " [0.         0.         0.         ... 1.1437874  0.         0.        ]\n",
      " [0.         0.         0.         ... 1.2547045  1.2031083  0.        ]]\n",
      "\n",
      "vgg: [[0.         0.01856048 0.         ... 0.         0.00395069 0.00929384]\n",
      " [0.         0.018339   0.         ... 0.         0.00394047 0.00920898]\n",
      " [0.         0.01834896 0.         ... 0.         0.00406163 0.00904012]\n",
      " ...\n",
      " [0.         0.01423693 0.         ... 0.         0.00508481 0.0128215 ]\n",
      " [0.         0.01374118 0.         ... 0.         0.00496024 0.01279762]\n",
      " [0.         0.01377589 0.         ... 0.         0.00491393 0.0126546 ]]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     22\u001b[0m vgg_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(features_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_CNN_VGG.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# 5\u001b[39;00m\n\u001b[1;32m     24\u001b[0m ptsd_binary \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCL-C (PTSD)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_boaw_ege\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(boaw_egemaps_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_boaw_mfcc\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(boaw_mfcc_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_egemaps\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(egemaps_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_mfcc\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(mfcc_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_vgg16\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg16_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_densenet\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(densenet_path)\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_bovw_of\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(bovw_openface_pg_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnumber)\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_of\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(openface_pg_path)\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnumber) \u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_resnet\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(resnet_path)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisual_vgg\u001b[39m\u001b[38;5;124m\"\u001b[39m: loadmat(vgg_path)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     37\u001b[0m }\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(p_id)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_egemaps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_egemaps\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f510f6-3c68-4d96-a3db-4af0a87d1ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
