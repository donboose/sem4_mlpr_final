{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04479d5e",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "# PTSD Prediction Preprocessing Pipeline (Batch Processing)\n",
    "\n",
    "This notebook implements the preprocessing pipeline with batch processing to avoid memory overload.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0170a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:00.071553Z",
     "iopub.status.busy": "2025-05-02T20:32:00.071330Z",
     "iopub.status.idle": "2025-05-02T20:32:00.074017Z",
     "shell.execute_reply": "2025-05-02T20:32:00.073624Z",
     "shell.execute_reply.started": "2025-05-02T20:32:00.071537Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import gc  # Garbage collection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import additional library for .mat file handling\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce9c2832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:01.944173Z",
     "iopub.status.busy": "2025-05-02T20:32:01.943951Z",
     "iopub.status.idle": "2025-05-02T20:32:01.950094Z",
     "shell.execute_reply": "2025-05-02T20:32:01.949760Z",
     "shell.execute_reply.started": "2025-05-02T20:32:01.944157Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "BASE_PATH = \"../../dataset/edaicwoz_participant\"\n",
    "LABELS_PATH = \"../../dataset/edaicwoz_labels\"\n",
    "OUTPUT_PATH = \"../../storage/sandeep/processed_data\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97116e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:03.488584Z",
     "iopub.status.busy": "2025-05-02T20:32:03.488340Z",
     "iopub.status.idle": "2025-05-02T20:32:03.496855Z",
     "shell.execute_reply": "2025-05-02T20:32:03.496529Z",
     "shell.execute_reply.started": "2025-05-02T20:32:03.488569Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Participant_ID   Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  \\\n",
      "0             302     male           0          4             0   \n",
      "1             303   female           0          0             0   \n",
      "2             304   female           0          6             0   \n",
      "3             305     male           0          7             0   \n",
      "4             307  female            0          4             0   \n",
      "\n",
      "   PTSD Severity  split  \n",
      "0           28.0  train  \n",
      "1           17.0  train  \n",
      "2           20.0  train  \n",
      "3           28.0  train  \n",
      "4           23.0  train  \n",
      "train: 49/163 PTSD positive (30.06%)\n",
      "dev: 17/56 PTSD positive (30.36%)\n",
      "test: 21/56 PTSD positive (37.50%)\n"
     ]
    }
   ],
   "source": [
    "# Load and analyze labels\n",
    "def load_labels(labels_path):\n",
    "    train_df = pd.read_csv(f\"{labels_path}/train_split.csv\")\n",
    "    dev_df = pd.read_csv(f\"{labels_path}/dev_split.csv\")\n",
    "    test_df = pd.read_csv(f\"{labels_path}/test_split.csv\")\n",
    "    train_df['split'] = 'train'\n",
    "    dev_df['split'] = 'dev'\n",
    "    test_df['split'] = 'test'\n",
    "    return pd.concat([train_df, dev_df, test_df], ignore_index=True)\n",
    "\n",
    "# Load labels and analyze distribution\n",
    "all_labels = load_labels(LABELS_PATH)\n",
    "print(all_labels.head())\n",
    "\n",
    "# Verify PTSD distribution by split\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    split_df = all_labels[all_labels['split'] == split]\n",
    "    if 'PCL-C (PTSD)' in split_df.columns:\n",
    "        ptsd_count = split_df['PCL-C (PTSD)'].sum()\n",
    "        total = len(split_df)\n",
    "        print(f\"{split}: {ptsd_count}/{total} PTSD positive ({ptsd_count/total*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb704a79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:05.319662Z",
     "iopub.status.busy": "2025-05-02T20:32:05.319415Z",
     "iopub.status.idle": "2025-05-02T20:32:05.325646Z",
     "shell.execute_reply": "2025-05-02T20:32:05.325299Z",
     "shell.execute_reply.started": "2025-05-02T20:32:05.319646Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Participant data loading function with memory optimization\n",
    "def load_participant_data(participant_id, base_path, features_to_load=None):\n",
    "    \"\"\"Load features for a participant with memory optimization\n",
    "    \n",
    "    Args:\n",
    "        participant_id: ID of the participant\n",
    "        base_path: Base path to dataset\n",
    "        features_to_load: List of feature types to load (None=all)\n",
    "    \"\"\"\n",
    "    p_dir = Path(f\"{base_path}/{participant_id}_P/{participant_id}_P\")\n",
    "    features_dir = p_dir / \"features\"\n",
    "    feature_data = {}\n",
    "    \n",
    "    # Default: load all feature types\n",
    "    if features_to_load is None:\n",
    "        features_to_load = ['egemaps', 'mfcc', 'densenet', 'openface', 'resnet', 'vgg']\n",
    "    \n",
    "    try:\n",
    "        # Load audio features conditionally\n",
    "        if 'egemaps' in features_to_load:\n",
    "            egemaps_path = features_dir / f\"{participant_id}_OpenSMILE2.3.0_egemaps.csv\"\n",
    "            if egemaps_path.exists():\n",
    "                try:\n",
    "                    # Try standard CSV loading first\n",
    "                    feature_data[\"egemaps\"] = pd.read_csv(egemaps_path)\n",
    "                    # Check if it's a single column CSV with semicolon delimiters\n",
    "                    if feature_data[\"egemaps\"].shape[1] == 1 and \";\" in str(feature_data[\"egemaps\"].iloc[0, 0]):\n",
    "                        feature_data[\"egemaps\"] = pd.read_csv(egemaps_path, delimiter=';')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading egemaps: {e}\")\n",
    "        \n",
    "        if 'mfcc' in features_to_load:\n",
    "            mfcc_path = features_dir / f\"{participant_id}_OpenSMILE2.3.0_mfcc.csv\"\n",
    "            if mfcc_path.exists():\n",
    "                try:\n",
    "                    feature_data[\"mfcc\"] = pd.read_csv(mfcc_path)\n",
    "                    if feature_data[\"mfcc\"].shape[1] == 1 and \";\" in str(feature_data[\"mfcc\"].iloc[0, 0]):\n",
    "                        feature_data[\"mfcc\"] = pd.read_csv(mfcc_path, delimiter=';')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading mfcc: {e}\")\n",
    "        \n",
    "        if 'densenet' in features_to_load:\n",
    "            densenet_path = features_dir / f\"{participant_id}_densenet201.csv\"\n",
    "            if densenet_path.exists():\n",
    "                feature_data[\"densenet\"] = pd.read_csv(densenet_path)\n",
    "        \n",
    "        if 'openface' in features_to_load:\n",
    "            openface_path = features_dir / f\"{participant_id}_OpenFace2.1.0_Pose_gaze_AUs.csv\"\n",
    "            if openface_path.exists():\n",
    "                feature_data[\"openface\"] = pd.read_csv(openface_path)\n",
    "        \n",
    "        if 'resnet' in features_to_load:\n",
    "            resnet_path = features_dir / f\"{participant_id}_CNN_ResNet.mat\"\n",
    "            if resnet_path.exists():\n",
    "                try:\n",
    "                    resnet_data = sio.loadmat(resnet_path)\n",
    "                    if 'features' in resnet_data:\n",
    "                        feature_data[\"resnet\"] = resnet_data['features']\n",
    "                    else:\n",
    "                        feature_keys = [k for k in resnet_data.keys() if not k.startswith('__')]\n",
    "                        if feature_keys:\n",
    "                            feature_data[\"resnet\"] = resnet_data[feature_keys[0]]\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading ResNet: {e}\")\n",
    "        \n",
    "        if 'vgg' in features_to_load:\n",
    "            vgg_path = features_dir / f\"{participant_id}_CNN_VGG.mat\"\n",
    "            if vgg_path.exists():\n",
    "                try:\n",
    "                    vgg_data = sio.loadmat(vgg_path)\n",
    "                    if 'features' in vgg_data:\n",
    "                        feature_data[\"vgg\"] = vgg_data['features']\n",
    "                    else:\n",
    "                        feature_keys = [k for k in vgg_data.keys() if not k.startswith('__')]\n",
    "                        if feature_keys:\n",
    "                            feature_data[\"vgg\"] = vgg_data[feature_keys[0]]\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading VGG: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"General error loading features for participant {participant_id}: {e}\")\n",
    "    \n",
    "    return feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72294058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:06.734984Z",
     "iopub.status.busy": "2025-05-02T20:32:06.734797Z",
     "iopub.status.idle": "2025-05-02T20:32:06.740080Z",
     "shell.execute_reply": "2025-05-02T20:32:06.739768Z",
     "shell.execute_reply.started": "2025-05-02T20:32:06.734969Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimize normalization function to reduce memory usage\n",
    "def normalize_features(feature_data):\n",
    "    if feature_data is None:\n",
    "        return None\n",
    "    \n",
    "    normalized_data = {}\n",
    "    for key, data in feature_data.items():\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # Keep only numeric columns\n",
    "            numeric_cols = data.select_dtypes(include=['number']).columns\n",
    "            if len(numeric_cols) > 0:\n",
    "                # Handle case for DataFrame with numeric columns\n",
    "                numeric_data = data[numeric_cols].fillna(0)\n",
    "                scaler = StandardScaler()\n",
    "                normalized_data[key] = scaler.fit_transform(numeric_data)\n",
    "                print(f\"Normalized {key}: shape {normalized_data[key].shape}\")\n",
    "                # Free memory\n",
    "                del data\n",
    "                gc.collect()\n",
    "            else:\n",
    "                print(f\"Warning: No numeric columns found in {key}\")\n",
    "                continue\n",
    "        elif isinstance(data, np.ndarray):\n",
    "            # Handle deep feature arrays\n",
    "            if data.dtype.kind in ['U', 'S', 'O']:\n",
    "                try:\n",
    "                    data = np.array(data, dtype=float)\n",
    "                except ValueError:\n",
    "                    print(f\"Error: Could not convert {key} to numeric. Skipping.\")\n",
    "                    continue\n",
    "            \n",
    "            # Use batched normalization for large arrays to save memory\n",
    "            if data.shape[0] > 10000 and data.shape[1] > 1000:\n",
    "                print(f\"Using batched normalization for large {key} array\")\n",
    "                # Calculate mean and std on sample\n",
    "                sample_size = min(10000, data.shape[0])\n",
    "                sample_indices = np.random.choice(data.shape[0], sample_size, replace=False)\n",
    "                sample = data[sample_indices]\n",
    "                mean = np.mean(sample, axis=0)\n",
    "                std = np.std(sample, axis=0)\n",
    "                std[std == 0] = 1.0  # Avoid division by zero\n",
    "                \n",
    "                # Normalize in batches\n",
    "                batch_size = 5000\n",
    "                normalized_data[key] = np.zeros_like(data)\n",
    "                for i in range(0, data.shape[0], batch_size):\n",
    "                    end = min(i + batch_size, data.shape[0])\n",
    "                    normalized_data[key][i:end] = (data[i:end] - mean) / std\n",
    "                    # Force garbage collection after each batch\n",
    "                    gc.collect()\n",
    "                \n",
    "                print(f\"Normalized {key}: shape {normalized_data[key].shape}\")\n",
    "                # Free memory\n",
    "                del data\n",
    "                gc.collect()\n",
    "            else:\n",
    "                # Regular normalization for smaller arrays\n",
    "                scaler = StandardScaler()\n",
    "                normalized_data[key] = scaler.fit_transform(data)\n",
    "                print(f\"Normalized {key}: shape {normalized_data[key].shape}\")\n",
    "                # Free memory\n",
    "                del data\n",
    "                gc.collect()\n",
    "        else:\n",
    "            print(f\"Warning: Unsupported data type for {key}. Skipping.\")\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99cf720a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:08.136855Z",
     "iopub.status.busy": "2025-05-02T20:32:08.136600Z",
     "iopub.status.idle": "2025-05-02T20:32:08.140103Z",
     "shell.execute_reply": "2025-05-02T20:32:08.139681Z",
     "shell.execute_reply.started": "2025-05-02T20:32:08.136838Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create sequences from preprocessed features\n",
    "def create_sequences(features, seq_length=20, stride=10):\n",
    "    \"\"\"Create sequences for LSTM input with memory efficiency\"\"\"\n",
    "    \n",
    "    # For large feature arrays, process in batches\n",
    "    if features.shape[0] > 50000:\n",
    "        print(f\"Processing large feature array of shape {features.shape} in batches\")\n",
    "        sequences = []\n",
    "        batch_size = 10000\n",
    "        \n",
    "        for start_idx in range(0, features.shape[0] - seq_length + 1, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, features.shape[0] - seq_length + 1)\n",
    "            for i in range(start_idx, end_idx, stride):\n",
    "                sequences.append(features[i:i+seq_length])\n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "            \n",
    "        return np.array(sequences)\n",
    "    else:\n",
    "        # Regular sequence creation for smaller arrays\n",
    "        sequences = []\n",
    "        for i in range(0, features.shape[0] - seq_length + 1, stride):\n",
    "            sequences.append(features[i:i+seq_length])\n",
    "        return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c843a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:09.530519Z",
     "iopub.status.busy": "2025-05-02T20:32:09.530336Z",
     "iopub.status.idle": "2025-05-02T20:32:09.533940Z",
     "shell.execute_reply": "2025-05-02T20:32:09.533603Z",
     "shell.execute_reply.started": "2025-05-02T20:32:09.530504Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create multimodal sequences with aligned time steps\n",
    "def create_multimodal_sequences(audio_features, visual_features, seq_length=20, stride=10):\n",
    "    \"\"\"Create aligned sequences from audio and visual features\"\"\"\n",
    "    # Determine the minimum length between modalities\n",
    "    min_length = min(audio_features.shape[0], visual_features.shape[0])\n",
    "    \n",
    "    # Initialize sequence lists\n",
    "    audio_sequences = []\n",
    "    visual_sequences = []\n",
    "    \n",
    "    # For very large feature arrays, process in batches\n",
    "    if min_length > 50000:\n",
    "        batch_size = 10000\n",
    "        for start_idx in range(0, min_length - seq_length + 1, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, min_length - seq_length + 1)\n",
    "            for i in range(start_idx, end_idx, stride):\n",
    "                if i + seq_length <= min_length:\n",
    "                    audio_sequences.append(audio_features[i:i+seq_length])\n",
    "                    visual_sequences.append(visual_features[i:i+seq_length])\n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "    else:\n",
    "        for i in range(0, min_length - seq_length + 1, stride):\n",
    "            audio_sequences.append(audio_features[i:i+seq_length])\n",
    "            visual_sequences.append(visual_features[i:i+seq_length])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    audio_array = np.array(audio_sequences)\n",
    "    visual_array = np.array(visual_sequences)\n",
    "    \n",
    "    return audio_array, visual_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf3b14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:10.943019Z",
     "iopub.status.busy": "2025-05-02T20:32:10.942788Z",
     "iopub.status.idle": "2025-05-02T20:32:10.945660Z",
     "shell.execute_reply": "2025-05-02T20:32:10.945334Z",
     "shell.execute_reply.started": "2025-05-02T20:32:10.943004Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract PTSD label using different approaches\n",
    "def get_ptsd_label(participant_info):\n",
    "    \"\"\"Extract PTSD label, prioritizing direct binary values\"\"\"\n",
    "    # First try to use provided binary classification\n",
    "    if 'PCL-C (PTSD)' in participant_info:\n",
    "        return int(participant_info['PCL-C (PTSD)'])\n",
    "    elif 'PCL-C' in participant_info:\n",
    "        return int(participant_info['PCL-C'])\n",
    "    elif 'PTSD' in participant_info:\n",
    "        return int(participant_info['PTSD'])\n",
    "    # Fallback to severity threshold\n",
    "    elif 'PTSD Severity' in participant_info:\n",
    "        severity = float(participant_info['PTSD Severity'])\n",
    "        return int(severity >= 35)  # Clinical threshold\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "596a3782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:12.394641Z",
     "iopub.status.busy": "2025-05-02T20:32:12.394392Z",
     "iopub.status.idle": "2025-05-02T20:32:12.399304Z",
     "shell.execute_reply": "2025-05-02T20:32:12.398929Z",
     "shell.execute_reply.started": "2025-05-02T20:32:12.394625Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process single participant with memory optimization\n",
    "def process_participant(participant_id, base_path, preferred_features=None):\n",
    "    \"\"\"Process a participant with memory optimization\n",
    "    \n",
    "    Args:\n",
    "        participant_id: Participant ID\n",
    "        base_path: Base path to dataset\n",
    "        preferred_features: Dictionary of preferred features for audio/visual\n",
    "    \"\"\"\n",
    "    # Default preferred features if not specified\n",
    "    if preferred_features is None:\n",
    "        preferred_features = {\n",
    "            'audio': ['egemaps', 'mfcc', 'densenet'],  # Try these in order\n",
    "            'visual': ['openface', 'resnet', 'vgg']    # Try these in order\n",
    "        }\n",
    "    \n",
    "    print(f\"Processing participant {participant_id}...\")\n",
    "    \n",
    "    # First load minimal feature set to determine availability\n",
    "    initial_features = load_participant_data(participant_id, base_path, \n",
    "                                             features_to_load=preferred_features['audio'][:1] + \n",
    "                                                          preferred_features['visual'][:1])\n",
    "    \n",
    "    # Check for minimum required features (one audio, one visual)\n",
    "    has_audio = any(f in initial_features for f in preferred_features['audio'])\n",
    "    has_visual = any(f in initial_features for f in preferred_features['visual'])\n",
    "    \n",
    "    if not has_audio or not has_visual:\n",
    "        print(f\"Participant {participant_id} missing required features\")\n",
    "        return None\n",
    "    \n",
    "    # Determine which features to use for this participant\n",
    "    audio_feature_to_use = None\n",
    "    for feature in preferred_features['audio']:\n",
    "        if feature in initial_features:\n",
    "            audio_feature_to_use = feature\n",
    "            break\n",
    "    \n",
    "    visual_feature_to_use = None\n",
    "    for feature in preferred_features['visual']:\n",
    "        if feature in initial_features:\n",
    "            visual_feature_to_use = feature\n",
    "            break\n",
    "    \n",
    "    # Clear memory of initial features\n",
    "    del initial_features\n",
    "    gc.collect()\n",
    "    \n",
    "    # Now load only the features we need\n",
    "    feature_data = load_participant_data(participant_id, base_path, \n",
    "                                         features_to_load=[audio_feature_to_use, visual_feature_to_use])\n",
    "    \n",
    "    # Normalize the features\n",
    "    normalized_features = normalize_features(feature_data)\n",
    "    if normalized_features is None or len(normalized_features) < 2:\n",
    "        print(f\"Failed to normalize features for participant {participant_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract audio and visual features\n",
    "    audio_features = normalized_features.get(audio_feature_to_use)\n",
    "    visual_features = normalized_features.get(visual_feature_to_use)\n",
    "    \n",
    "    if audio_features is None or visual_features is None:\n",
    "        print(f\"Missing required features after normalization for participant {participant_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Create aligned sequences\n",
    "    audio_sequences, visual_sequences = create_multimodal_sequences(\n",
    "        audio_features, visual_features, seq_length=20, stride=10\n",
    "    )\n",
    "    \n",
    "    # Clear memory\n",
    "    del normalized_features\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"Created {len(audio_sequences)} sequences for participant {participant_id}\")\n",
    "    \n",
    "    return {\n",
    "        'audio_sequences': audio_sequences,\n",
    "        'visual_sequences': visual_sequences,\n",
    "        'audio_feature': audio_feature_to_use,\n",
    "        'visual_feature': visual_feature_to_use\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "926ad881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:13.737808Z",
     "iopub.status.busy": "2025-05-02T20:32:13.737557Z",
     "iopub.status.idle": "2025-05-02T20:32:13.743802Z",
     "shell.execute_reply": "2025-05-02T20:32:13.743456Z",
     "shell.execute_reply.started": "2025-05-02T20:32:13.737792Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process full dataset in batches to avoid memory issues\n",
    "def process_full_dataset_batched(base_path, labels_path, output_path):\n",
    "    \"\"\"Process the full dataset in batches by split\"\"\"\n",
    "    # Load labels\n",
    "    all_labels = load_labels(labels_path)\n",
    "    \n",
    "    # Define feature preferences\n",
    "    # Order matters - will try to use first available feature in each list\n",
    "    preferred_features = {\n",
    "        'audio': ['egemaps', 'mfcc', 'densenet'],  # In order of preference\n",
    "        'visual': ['openface', 'resnet', 'vgg']    # In order of preference\n",
    "    }\n",
    "    \n",
    "    # Process each split separately to manage memory\n",
    "    for split in ['train', 'dev', 'test']:\n",
    "        print(f\"\\nProcessing {split} set...\")\n",
    "        \n",
    "        # Get participant IDs for this split\n",
    "        split_df = all_labels[all_labels['split'] == split]\n",
    "        participant_ids = split_df['Participant_ID'].astype(str).tolist()\n",
    "        \n",
    "        # Initialize lists to store data\n",
    "        audio_sequences = []\n",
    "        visual_sequences = []\n",
    "        labels = []\n",
    "        participant_ids_processed = []\n",
    "        \n",
    "        # Process participants in small batches\n",
    "        batch_size = 10  # Process 10 participants at a time\n",
    "        for batch_start in range(0, len(participant_ids), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(participant_ids))\n",
    "            batch_ids = participant_ids[batch_start:batch_end]\n",
    "            \n",
    "            print(f\"Processing batch {batch_start//batch_size + 1}/{(len(participant_ids)-1)//batch_size + 1} in {split} set\")\n",
    "            \n",
    "            batch_audio = []\n",
    "            batch_visual = []\n",
    "            batch_labels = []\n",
    "            batch_pids = []\n",
    "            \n",
    "            for pid in batch_ids:\n",
    "                # Get PTSD label\n",
    "                p_info = all_labels[all_labels['Participant_ID'].astype(str) == pid].iloc[0]\n",
    "                ptsd_label = get_ptsd_label(p_info)\n",
    "                \n",
    "                # Process participant\n",
    "                result = process_participant(pid, base_path, preferred_features)\n",
    "                if result is None:\n",
    "                    continue\n",
    "                \n",
    "                # Extract sequences\n",
    "                audio_seqs = result['audio_sequences']\n",
    "                visual_seqs = result['visual_sequences']\n",
    "                \n",
    "                # Add to batch lists\n",
    "                batch_audio.append(audio_seqs)\n",
    "                batch_visual.append(visual_seqs)\n",
    "                batch_labels.extend([ptsd_label] * len(audio_seqs))\n",
    "                batch_pids.extend([pid] * len(audio_seqs))\n",
    "                \n",
    "                # Clear memory\n",
    "                del result\n",
    "                gc.collect()\n",
    "            \n",
    "            # Combine sequences from this batch\n",
    "            if batch_audio:\n",
    "                audio_sequences.extend(np.vstack(batch_audio))\n",
    "                visual_sequences.extend(np.vstack(batch_visual))\n",
    "                labels.extend(batch_labels)\n",
    "                participant_ids_processed.extend(batch_pids)\n",
    "            \n",
    "            # Clear batch memory\n",
    "            del batch_audio, batch_visual, batch_labels, batch_pids\n",
    "            gc.collect()\n",
    "            \n",
    "            # Save intermediate results for this batch\n",
    "            if audio_sequences:\n",
    "                print(f\"Saving intermediate results for {split} after batch {batch_start//batch_size + 1}\")\n",
    "                \n",
    "                # Convert to numpy arrays\n",
    "                audio_array = np.array(audio_sequences)\n",
    "                visual_array = np.array(visual_sequences)\n",
    "                labels_array = np.array(labels)\n",
    "                \n",
    "                # Create dataset dict\n",
    "                interim_dataset = {\n",
    "                    'audio': audio_array,\n",
    "                    'visual': visual_array,\n",
    "                    'labels': labels_array,\n",
    "                    'participant_ids': participant_ids_processed\n",
    "                }\n",
    "                \n",
    "                # Save intermediate results\n",
    "                os.makedirs(output_path, exist_ok=True)\n",
    "                with open(f\"{output_path}/{split}_batch_{batch_start//batch_size + 1}.pkl\", 'wb') as f:\n",
    "                    pickle.dump(interim_dataset, f)\n",
    "                \n",
    "                # Clear memory\n",
    "                del audio_array, visual_array, labels_array, interim_dataset\n",
    "                audio_sequences = []\n",
    "                visual_sequences = []\n",
    "                labels = []\n",
    "                participant_ids_processed = []\n",
    "                gc.collect()\n",
    "        \n",
    "        # Combine all batch files for this split\n",
    "        combine_batch_files(split, output_path)\n",
    "    \n",
    "    print(\"\\nDataset processing complete!\")\n",
    "    print_dataset_statistics(output_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241dfda5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:15.202706Z",
     "iopub.status.busy": "2025-05-02T20:32:15.202352Z",
     "iopub.status.idle": "2025-05-02T20:32:15.208510Z",
     "shell.execute_reply": "2025-05-02T20:32:15.208191Z",
     "shell.execute_reply.started": "2025-05-02T20:32:15.202690Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to combine batch files with extreme memory optimization\n",
    "def combine_batch_files(split, output_path):\n",
    "    \"\"\"Combine batch files in a super memory-efficient way\"\"\"\n",
    "    print(f\"Combining batch files for {split}...\")\n",
    "    \n",
    "    # Find all batch files for this split\n",
    "    batch_files = sorted([f for f in os.listdir(output_path) \n",
    "                         if f.startswith(f\"{split}_batch_\") and f.endswith(\".pkl\")])\n",
    "    \n",
    "    if not batch_files:\n",
    "        print(f\"No batch files found for {split}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(batch_files)} batch files for {split}\")\n",
    "    \n",
    "    # Initialize empty arrays for final dataset\n",
    "    all_audio = None \n",
    "    all_visual = None\n",
    "    all_labels = []\n",
    "    all_pids = []\n",
    "    total_sequences = 0\n",
    "    ptsd_positive = 0\n",
    "    \n",
    "    # Create a combined file incrementally\n",
    "    for i, batch_file in enumerate(batch_files):\n",
    "        print(f\"Processing batch file {i+1}/{len(batch_files)}: {batch_file}\")\n",
    "        \n",
    "        # Load batch file\n",
    "        with open(f\"{output_path}/{batch_file}\", 'rb') as f:\n",
    "            batch_data = pickle.load(f)\n",
    "        \n",
    "        # Get data\n",
    "        batch_audio = batch_data['audio']\n",
    "        batch_visual = batch_data['visual']\n",
    "        batch_labels = batch_data['labels']\n",
    "        batch_pids = batch_data['participant_ids']\n",
    "        \n",
    "        # Track statistics\n",
    "        total_sequences += len(batch_labels)\n",
    "        ptsd_positive += sum(batch_labels)\n",
    "        \n",
    "        # Combine incrementally\n",
    "        if all_audio is None:\n",
    "            # First batch - create initial combined files\n",
    "            all_audio_file = f\"{output_path}/{split}_audio.npy\"\n",
    "            all_visual_file = f\"{output_path}/{split}_visual.npy\"\n",
    "            \n",
    "            # Save initial arrays\n",
    "            np.save(all_audio_file, batch_audio)\n",
    "            np.save(all_visual_file, batch_visual)\n",
    "        else:\n",
    "            # For subsequent batches, load existing data, append new data, and save back\n",
    "            # We do this in a very memory efficient way\n",
    "            \n",
    "            # Audio sequences\n",
    "            all_audio_file = f\"{output_path}/{split}_audio.npy\"\n",
    "            combined_audio = np.vstack([np.load(all_audio_file, mmap_mode='r'), batch_audio])\n",
    "            np.save(all_audio_file, combined_audio)\n",
    "            del combined_audio\n",
    "            \n",
    "            # Visual sequences\n",
    "            all_visual_file = f\"{output_path}/{split}_visual.npy\"\n",
    "            combined_visual = np.vstack([np.load(all_visual_file, mmap_mode='r'), batch_visual])\n",
    "            np.save(all_visual_file, combined_visual)\n",
    "            del combined_visual\n",
    "        \n",
    "        # Extend labels and participant IDs (these are smaller and can be kept in memory)\n",
    "        all_labels.extend(batch_labels)\n",
    "        all_pids.extend(batch_pids)\n",
    "        \n",
    "        # Delete batch data to free memory\n",
    "        del batch_data, batch_audio, batch_visual, batch_labels, batch_pids\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Current progress: {total_sequences} sequences, {ptsd_positive} PTSD positive\")\n",
    "    \n",
    "    # Save labels and participant IDs separately\n",
    "    with open(f\"{output_path}/{split}_labels.pkl\", 'wb') as f:\n",
    "        pickle.dump({'labels': all_labels, 'participant_ids': all_pids}, f)\n",
    "    \n",
    "    # Save metadata about the dataset dimensions\n",
    "    audio_shape = (total_sequences, 20, 24)  # Standard shape based on processing\n",
    "    visual_shape = (total_sequences, 20, 53)  # Standard shape based on processing\n",
    "    \n",
    "    with open(f\"{output_path}/{split}_metadata.pkl\", 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'audio_shape': audio_shape,\n",
    "            'visual_shape': visual_shape,\n",
    "            'total_sequences': total_sequences,\n",
    "            'ptsd_positive': ptsd_positive,\n",
    "            'ptsd_percentage': (ptsd_positive/total_sequences*100) if total_sequences > 0 else 0\n",
    "        }, f)\n",
    "    \n",
    "    print(f\"Combined {split} data saved with {total_sequences} sequences\")\n",
    "    print(f\"PTSD positive: {ptsd_positive}/{total_sequences} ({ptsd_positive/total_sequences*100:.2f}%)\")\n",
    "    \n",
    "    # Remove batch files to save disk space\n",
    "    for batch_file in batch_files:\n",
    "        try:\n",
    "            os.remove(f\"{output_path}/{batch_file}\")\n",
    "            print(f\"Removed {batch_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {batch_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c725aa34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:21.629321Z",
     "iopub.status.busy": "2025-05-02T20:32:21.629143Z",
     "iopub.status.idle": "2025-05-02T20:32:21.632440Z",
     "shell.execute_reply": "2025-05-02T20:32:21.632008Z",
     "shell.execute_reply.started": "2025-05-02T20:32:21.629306Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to print dataset statistics\n",
    "def print_dataset_statistics(output_path):\n",
    "    \"\"\"Print statistics about the processed dataset\"\"\"\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    \n",
    "    # Load and analyze each split\n",
    "    for split in ['train', 'dev', 'test']:\n",
    "        split_file = f\"{output_path}/{split}_data.pkl\"\n",
    "        if not os.path.exists(split_file):\n",
    "            print(f\"{split} data file not found\")\n",
    "            continue\n",
    "        \n",
    "        # Load split data\n",
    "        with open(split_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"\\n{split.upper()} SET:\")\n",
    "        print(f\"  Audio sequences: {data['audio'].shape}\")\n",
    "        print(f\"  Visual sequences: {data['visual'].shape}\")\n",
    "        print(f\"  PTSD positive: {sum(data['labels'])}/{len(data['labels'])} \"\n",
    "              f\"({sum(data['labels'])/len(data['labels'])*100:.2f}%)\")\n",
    "        print(f\"  Unique participants: {len(set(data['participant_ids']))}\")\n",
    "        \n",
    "        # Free memory\n",
    "        del data\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44aa00b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:32:25.140574Z",
     "iopub.status.busy": "2025-05-02T20:32:25.140324Z",
     "iopub.status.idle": "2025-05-02T20:36:54.117678Z",
     "shell.execute_reply": "2025-05-02T20:36:54.117389Z",
     "shell.execute_reply.started": "2025-05-02T20:32:25.140559Z"
    },
    "language": "python",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing train set...\n",
      "Processing batch 1/17 in train set\n",
      "Processing participant 302...\n",
      "Normalized egemaps: shape (75876, 24)\n",
      "Normalized openface: shape (22766, 53)\n",
      "Created 2275 sequences for participant 302\n",
      "Processing participant 303...\n",
      "Normalized egemaps: shape (98526, 24)\n",
      "Normalized openface: shape (29565, 53)\n",
      "Created 2955 sequences for participant 303\n",
      "Processing participant 304...\n",
      "Normalized egemaps: shape (79256, 24)\n",
      "Normalized openface: shape (23780, 53)\n",
      "Created 2377 sequences for participant 304\n",
      "Processing participant 305...\n",
      "Normalized egemaps: shape (170396, 24)\n",
      "Normalized openface: shape (51122, 53)\n",
      "Created 5111 sequences for participant 305\n",
      "Processing participant 307...\n",
      "Normalized egemaps: shape (123872, 24)\n",
      "Normalized openface: shape (37167, 53)\n",
      "Created 3715 sequences for participant 307\n",
      "Processing participant 308...\n",
      "Normalized egemaps: shape (86756, 24)\n",
      "Normalized openface: shape (26031, 53)\n",
      "Created 2602 sequences for participant 308\n",
      "Processing participant 309...\n",
      "Normalized egemaps: shape (70559, 24)\n",
      "Normalized openface: shape (21391, 53)\n",
      "Created 2138 sequences for participant 309\n",
      "Processing participant 310...\n",
      "Normalized egemaps: shape (84468, 24)\n",
      "Normalized openface: shape (25609, 53)\n",
      "Created 2559 sequences for participant 310\n",
      "Processing participant 311...\n",
      "Normalized egemaps: shape (78542, 24)\n",
      "Normalized openface: shape (23810, 53)\n",
      "Created 2380 sequences for participant 311\n",
      "Processing participant 312...\n",
      "Normalized egemaps: shape (78992, 24)\n",
      "Normalized openface: shape (23945, 53)\n",
      "Created 2393 sequences for participant 312\n",
      "Saving intermediate results for train after batch 1\n",
      "Processing batch 2/17 in train set\n",
      "Processing participant 313...\n",
      "Normalized egemaps: shape (75372, 24)\n",
      "Normalized openface: shape (22848, 53)\n",
      "Created 2283 sequences for participant 313\n",
      "Processing participant 314...\n",
      "Normalized egemaps: shape (154649, 24)\n",
      "Normalized openface: shape (46873, 53)\n",
      "Created 4686 sequences for participant 314\n",
      "Processing participant 315...\n",
      "Normalized egemaps: shape (97522, 24)\n",
      "Normalized openface: shape (29561, 53)\n",
      "Created 2955 sequences for participant 315\n",
      "Processing participant 316...\n",
      "Normalized egemaps: shape (86877, 24)\n",
      "Normalized openface: shape (26337, 53)\n",
      "Created 2632 sequences for participant 316\n",
      "Processing participant 318...\n",
      "Normalized egemaps: shape (58836, 24)\n",
      "Normalized openface: shape (17833, 53)\n",
      "Created 1782 sequences for participant 318\n",
      "Processing participant 319...\n",
      "Normalized egemaps: shape (67966, 24)\n",
      "Normalized openface: shape (20603, 53)\n",
      "Created 2059 sequences for participant 319\n",
      "Processing participant 322...\n",
      "Normalized egemaps: shape (104706, 24)\n",
      "Normalized openface: shape (31412, 53)\n",
      "Created 3140 sequences for participant 322\n",
      "Processing participant 323...\n",
      "Normalized egemaps: shape (83696, 24)\n",
      "Normalized openface: shape (25110, 53)\n",
      "Created 2510 sequences for participant 323\n",
      "Processing participant 324...\n",
      "Normalized egemaps: shape (72126, 24)\n",
      "Normalized openface: shape (21640, 53)\n",
      "Created 2163 sequences for participant 324\n",
      "Processing participant 325...\n",
      "Normalized egemaps: shape (87496, 24)\n",
      "Normalized openface: shape (26251, 53)\n",
      "Created 2624 sequences for participant 325\n",
      "Saving intermediate results for train after batch 2\n",
      "Processing batch 3/17 in train set\n",
      "Processing participant 326...\n",
      "Normalized egemaps: shape (69901, 24)\n",
      "Normalized openface: shape (20982, 53)\n",
      "Created 2097 sequences for participant 326\n",
      "Processing participant 327...\n",
      "Normalized egemaps: shape (68073, 24)\n",
      "Normalized openface: shape (20427, 53)\n",
      "Created 2041 sequences for participant 327\n",
      "Processing participant 328...\n",
      "Normalized egemaps: shape (106509, 24)\n",
      "Normalized openface: shape (31956, 53)\n",
      "Created 3194 sequences for participant 328\n",
      "Processing participant 329...\n",
      "Normalized egemaps: shape (70619, 24)\n",
      "Normalized openface: shape (21192, 53)\n",
      "Created 2118 sequences for participant 329\n",
      "Processing participant 330...\n",
      "Normalized egemaps: shape (77146, 24)\n",
      "Normalized openface: shape (23146, 53)\n",
      "Created 2313 sequences for participant 330\n",
      "Processing participant 332...\n",
      "Normalized egemaps: shape (87406, 24)\n",
      "Normalized openface: shape (26228, 53)\n",
      "Created 2621 sequences for participant 332\n",
      "Processing participant 333...\n",
      "Normalized egemaps: shape (96926, 24)\n",
      "Normalized openface: shape (29081, 53)\n",
      "Created 2907 sequences for participant 333\n",
      "Processing participant 335...\n",
      "Normalized egemaps: shape (83006, 24)\n",
      "Normalized openface: shape (24902, 53)\n",
      "Created 2489 sequences for participant 335\n",
      "Processing participant 337...\n",
      "Normalized egemaps: shape (187116, 24)\n",
      "Normalized openface: shape (56137, 53)\n",
      "Created 5612 sequences for participant 337\n",
      "Processing participant 338...\n",
      "Normalized egemaps: shape (59676, 24)\n",
      "Normalized openface: shape (17906, 53)\n",
      "Created 1789 sequences for participant 338\n",
      "Saving intermediate results for train after batch 3\n",
      "Processing batch 4/17 in train set\n",
      "Processing participant 339...\n",
      "Normalized egemaps: shape (86286, 24)\n",
      "Normalized openface: shape (25892, 53)\n",
      "Created 2588 sequences for participant 339\n",
      "Processing participant 340...\n",
      "Normalized egemaps: shape (59916, 24)\n",
      "Normalized openface: shape (17980, 53)\n",
      "Created 1797 sequences for participant 340\n",
      "Processing participant 341...\n",
      "Normalized egemaps: shape (86736, 24)\n",
      "Normalized openface: shape (26027, 53)\n",
      "Created 2601 sequences for participant 341\n",
      "Processing participant 345...\n",
      "Normalized egemaps: shape (79386, 24)\n",
      "Normalized openface: shape (23818, 53)\n",
      "Created 2380 sequences for participant 345\n",
      "Processing participant 346...\n",
      "Normalized egemaps: shape (122176, 24)\n",
      "Normalized openface: shape (36656, 53)\n",
      "Created 3664 sequences for participant 346\n",
      "Processing participant 348...\n",
      "Normalized egemaps: shape (71935, 24)\n",
      "Normalized openface: shape (21584, 53)\n",
      "Created 2157 sequences for participant 348\n",
      "Processing participant 349...\n",
      "Normalized egemaps: shape (121582, 24)\n",
      "Normalized openface: shape (36479, 53)\n",
      "Created 3646 sequences for participant 349\n",
      "Processing participant 351...\n",
      "Normalized egemaps: shape (76956, 24)\n",
      "Normalized openface: shape (23090, 53)\n",
      "Created 2308 sequences for participant 351\n",
      "Processing participant 352...\n",
      "Normalized egemaps: shape (76003, 24)\n",
      "Normalized openface: shape (22808, 53)\n",
      "Created 2279 sequences for participant 352\n",
      "Processing participant 353...\n",
      "Normalized egemaps: shape (78592, 24)\n",
      "Normalized openface: shape (23584, 53)\n",
      "Created 2357 sequences for participant 353\n",
      "Saving intermediate results for train after batch 4\n",
      "Processing batch 5/17 in train set\n",
      "Processing participant 354...\n",
      "Normalized egemaps: shape (57661, 24)\n",
      "Normalized openface: shape (17306, 53)\n",
      "Created 1729 sequences for participant 354\n",
      "Processing participant 355...\n",
      "Normalized egemaps: shape (67460, 24)\n",
      "Normalized openface: shape (20242, 53)\n",
      "Created 2023 sequences for participant 355\n",
      "Processing participant 356...\n",
      "Normalized egemaps: shape (95377, 24)\n",
      "Normalized openface: shape (28624, 53)\n",
      "Created 2861 sequences for participant 356\n",
      "Processing participant 357...\n",
      "Normalized egemaps: shape (41468, 24)\n",
      "Normalized openface: shape (12447, 53)\n",
      "Created 1243 sequences for participant 357\n",
      "Processing participant 358...\n",
      "Normalized egemaps: shape (64780, 24)\n",
      "Normalized openface: shape (19438, 53)\n",
      "Created 1942 sequences for participant 358\n",
      "Processing participant 359...\n",
      "Normalized egemaps: shape (103356, 24)\n",
      "Normalized openface: shape (31012, 53)\n",
      "Created 3100 sequences for participant 359\n",
      "Processing participant 360...\n",
      "Normalized egemaps: shape (44021, 24)\n",
      "Normalized openface: shape (13214, 53)\n",
      "Created 1320 sequences for participant 360\n",
      "Processing participant 361...\n",
      "Normalized egemaps: shape (64174, 24)\n",
      "Normalized openface: shape (19260, 53)\n",
      "Created 1925 sequences for participant 361\n",
      "Processing participant 362...\n",
      "Normalized egemaps: shape (59013, 24)\n",
      "Normalized openface: shape (17710, 53)\n",
      "Created 1770 sequences for participant 362\n",
      "Processing participant 363...\n",
      "Normalized egemaps: shape (122706, 24)\n",
      "Normalized openface: shape (36814, 53)\n",
      "Created 3680 sequences for participant 363\n",
      "Saving intermediate results for train after batch 5\n",
      "Processing batch 6/17 in train set\n",
      "Processing participant 364...\n",
      "Normalized egemaps: shape (178129, 24)\n",
      "Normalized openface: shape (53447, 53)\n",
      "Created 5343 sequences for participant 364\n",
      "Processing participant 366...\n",
      "Normalized egemaps: shape (131266, 24)\n",
      "Normalized openface: shape (39381, 53)\n",
      "Created 3937 sequences for participant 366\n",
      "Processing participant 367...\n",
      "Normalized egemaps: shape (163678, 24)\n",
      "Normalized openface: shape (49112, 53)\n",
      "Created 4910 sequences for participant 367\n",
      "Processing participant 368...\n",
      "Normalized egemaps: shape (135457, 24)\n",
      "Normalized openface: shape (40645, 53)\n",
      "Created 4063 sequences for participant 368\n",
      "Processing participant 369...\n",
      "Normalized egemaps: shape (104101, 24)\n",
      "Normalized openface: shape (31236, 53)\n",
      "Created 3122 sequences for participant 369\n",
      "Processing participant 370...\n",
      "Normalized egemaps: shape (120842, 24)\n",
      "Normalized openface: shape (36262, 53)\n",
      "Created 3625 sequences for participant 370\n",
      "Processing participant 372...\n",
      "Normalized egemaps: shape (151364, 24)\n",
      "Normalized openface: shape (45416, 53)\n",
      "Created 4540 sequences for participant 372\n",
      "Processing participant 375...\n",
      "Normalized egemaps: shape (62099, 24)\n",
      "Normalized openface: shape (18636, 53)\n",
      "Created 1862 sequences for participant 375\n",
      "Processing participant 376...\n",
      "Normalized egemaps: shape (102566, 24)\n",
      "Normalized openface: shape (30772, 53)\n",
      "Created 3076 sequences for participant 376\n",
      "Processing participant 377...\n",
      "Normalized egemaps: shape (132808, 24)\n",
      "Normalized openface: shape (39851, 53)\n",
      "Created 3984 sequences for participant 377\n",
      "Saving intermediate results for train after batch 6\n",
      "Processing batch 7/17 in train set\n",
      "Processing participant 378...\n",
      "Normalized egemaps: shape (87330, 24)\n",
      "Normalized openface: shape (26208, 53)\n",
      "Created 2619 sequences for participant 378\n",
      "Processing participant 379...\n",
      "Normalized egemaps: shape (100188, 24)\n",
      "Normalized openface: shape (30065, 53)\n",
      "Created 3005 sequences for participant 379\n",
      "Processing participant 380...\n",
      "Normalized egemaps: shape (196597, 24)\n",
      "Normalized openface: shape (58989, 53)\n",
      "Created 5897 sequences for participant 380\n",
      "Processing participant 383...\n",
      "Normalized egemaps: shape (136906, 24)\n",
      "Normalized openface: shape (41074, 53)\n",
      "Created 4106 sequences for participant 383\n",
      "Processing participant 384...\n",
      "Normalized egemaps: shape (105676, 24)\n",
      "Normalized openface: shape (31707, 53)\n",
      "Created 3169 sequences for participant 384\n",
      "Processing participant 385...\n",
      "Normalized egemaps: shape (53610, 24)\n",
      "Normalized openface: shape (16091, 53)\n",
      "Created 1608 sequences for participant 385\n",
      "Processing participant 386...\n",
      "Normalized egemaps: shape (103922, 24)\n",
      "Normalized openface: shape (31185, 53)\n",
      "Created 3117 sequences for participant 386\n",
      "Processing participant 387...\n",
      "Normalized egemaps: shape (60268, 24)\n",
      "Normalized openface: shape (18084, 53)\n",
      "Created 1807 sequences for participant 387\n",
      "Processing participant 389...\n",
      "Normalized egemaps: shape (95315, 24)\n",
      "Normalized openface: shape (28597, 53)\n",
      "Created 2858 sequences for participant 389\n",
      "Processing participant 390...\n",
      "Normalized egemaps: shape (135652, 24)\n",
      "Normalized openface: shape (40703, 53)\n",
      "Created 4069 sequences for participant 390\n",
      "Saving intermediate results for train after batch 7\n",
      "Processing batch 8/17 in train set\n",
      "Processing participant 391...\n",
      "Normalized egemaps: shape (67995, 24)\n",
      "Normalized openface: shape (20405, 53)\n",
      "Created 2039 sequences for participant 391\n",
      "Processing participant 392...\n",
      "Normalized egemaps: shape (65550, 24)\n",
      "Normalized openface: shape (19671, 53)\n",
      "Created 1966 sequences for participant 392\n",
      "Processing participant 395...\n",
      "Normalized egemaps: shape (88901, 24)\n",
      "Normalized openface: shape (26678, 53)\n",
      "Created 2666 sequences for participant 395\n",
      "Processing participant 396...\n",
      "Normalized egemaps: shape (78017, 24)\n",
      "Normalized openface: shape (23413, 53)\n",
      "Created 2340 sequences for participant 396\n",
      "Processing participant 397...\n",
      "Normalized egemaps: shape (95310, 24)\n",
      "Normalized openface: shape (28599, 53)\n",
      "Created 2858 sequences for participant 397\n",
      "Processing participant 399...\n",
      "Normalized egemaps: shape (73392, 24)\n",
      "Normalized openface: shape (22022, 53)\n",
      "Created 2201 sequences for participant 399\n",
      "Processing participant 400...\n",
      "Normalized egemaps: shape (93666, 24)\n",
      "Normalized openface: shape (28104, 53)\n",
      "Created 2809 sequences for participant 400\n",
      "Processing participant 403...\n",
      "Normalized egemaps: shape (86228, 24)\n",
      "Normalized openface: shape (25878, 53)\n",
      "Created 2586 sequences for participant 403\n",
      "Processing participant 404...\n",
      "Normalized egemaps: shape (113056, 24)\n",
      "Normalized openface: shape (33920, 53)\n",
      "Created 3391 sequences for participant 404\n",
      "Processing participant 405...\n",
      "Normalized egemaps: shape (157003, 24)\n",
      "Normalized openface: shape (47107, 53)\n",
      "Created 4709 sequences for participant 405\n",
      "Saving intermediate results for train after batch 8\n",
      "Processing batch 9/17 in train set\n",
      "Processing participant 406...\n",
      "Normalized egemaps: shape (72164, 24)\n",
      "Normalized openface: shape (21656, 53)\n",
      "Created 2164 sequences for participant 406\n",
      "Processing participant 407...\n",
      "Normalized egemaps: shape (125233, 24)\n",
      "Normalized openface: shape (37575, 53)\n",
      "Created 3756 sequences for participant 407\n",
      "Processing participant 409...\n",
      "Normalized egemaps: shape (103224, 24)\n",
      "Normalized openface: shape (30974, 53)\n",
      "Created 3096 sequences for participant 409\n",
      "Processing participant 410...\n",
      "Normalized egemaps: shape (106495, 24)\n",
      "Normalized openface: shape (31951, 53)\n",
      "Created 3194 sequences for participant 410\n",
      "Processing participant 411...\n",
      "Normalized egemaps: shape (138278, 24)\n",
      "Normalized openface: shape (41492, 53)\n",
      "Created 4148 sequences for participant 411\n",
      "Processing participant 413...\n",
      "Normalized egemaps: shape (99676, 24)\n",
      "Normalized openface: shape (29906, 53)\n",
      "Created 2989 sequences for participant 413\n",
      "Processing participant 414...\n",
      "Normalized egemaps: shape (98407, 24)\n",
      "Normalized openface: shape (29532, 53)\n",
      "Created 2952 sequences for participant 414\n",
      "Processing participant 416...\n",
      "Normalized egemaps: shape (86559, 24)\n",
      "Normalized openface: shape (25977, 53)\n",
      "Created 2596 sequences for participant 416\n",
      "Processing participant 417...\n",
      "Normalized egemaps: shape (88625, 24)\n",
      "Normalized openface: shape (26590, 53)\n",
      "Created 2658 sequences for participant 417\n",
      "Processing participant 418...\n",
      "Normalized egemaps: shape (108916, 24)\n",
      "Normalized openface: shape (32680, 53)\n",
      "Created 3267 sequences for participant 418\n",
      "Saving intermediate results for train after batch 9\n",
      "Processing batch 10/17 in train set\n",
      "Processing participant 419...\n",
      "Normalized egemaps: shape (90626, 24)\n",
      "Normalized openface: shape (27189, 53)\n",
      "Created 2717 sequences for participant 419\n",
      "Processing participant 420...\n",
      "Normalized egemaps: shape (104879, 24)\n",
      "Normalized openface: shape (31468, 53)\n",
      "Created 3145 sequences for participant 420\n",
      "Processing participant 421...\n",
      "Normalized egemaps: shape (83681, 24)\n",
      "Normalized openface: shape (25110, 53)\n",
      "Created 2510 sequences for participant 421\n",
      "Processing participant 422...\n",
      "Normalized egemaps: shape (133453, 24)\n",
      "Normalized openface: shape (40039, 53)\n",
      "Created 4002 sequences for participant 422\n",
      "Processing participant 424...\n",
      "Normalized egemaps: shape (106256, 24)\n",
      "Normalized openface: shape (31881, 53)\n",
      "Created 3187 sequences for participant 424\n",
      "Processing participant 426...\n",
      "Normalized egemaps: shape (85664, 24)\n",
      "Normalized openface: shape (25704, 53)\n",
      "Created 2569 sequences for participant 426\n",
      "Processing participant 427...\n",
      "Normalized egemaps: shape (87160, 24)\n",
      "Normalized openface: shape (26154, 53)\n",
      "Created 2614 sequences for participant 427\n",
      "Processing participant 428...\n",
      "Normalized egemaps: shape (70396, 24)\n",
      "Normalized openface: shape (21127, 53)\n",
      "Created 2111 sequences for participant 428\n",
      "Processing participant 429...\n",
      "Normalized egemaps: shape (95740, 24)\n",
      "Normalized openface: shape (28726, 53)\n",
      "Created 2871 sequences for participant 429\n",
      "Processing participant 430...\n",
      "Normalized egemaps: shape (90861, 24)\n",
      "Normalized openface: shape (27264, 53)\n",
      "Created 2725 sequences for participant 430\n",
      "Saving intermediate results for train after batch 10\n",
      "Processing batch 11/17 in train set\n",
      "Processing participant 432...\n",
      "Normalized egemaps: shape (93571, 24)\n",
      "Normalized openface: shape (28079, 53)\n",
      "Created 2806 sequences for participant 432\n",
      "Processing participant 434...\n",
      "Normalized egemaps: shape (131967, 24)\n",
      "Normalized openface: shape (39597, 53)\n",
      "Created 3958 sequences for participant 434\n",
      "Processing participant 436...\n",
      "Normalized egemaps: shape (68780, 24)\n",
      "Normalized openface: shape (20637, 53)\n",
      "Created 2062 sequences for participant 436\n",
      "Processing participant 438...\n",
      "Normalized egemaps: shape (142970, 24)\n",
      "Normalized openface: shape (42901, 53)\n",
      "Created 4289 sequences for participant 438\n",
      "Processing participant 439...\n",
      "Normalized egemaps: shape (128447, 24)\n",
      "Normalized openface: shape (38541, 53)\n",
      "Created 3853 sequences for participant 439\n",
      "Processing participant 440...\n",
      "Normalized egemaps: shape (141389, 24)\n",
      "Normalized openface: shape (42426, 53)\n",
      "Created 4241 sequences for participant 440\n",
      "Processing participant 443...\n",
      "Normalized egemaps: shape (70120, 24)\n",
      "Normalized openface: shape (21040, 53)\n",
      "Created 2103 sequences for participant 443\n",
      "Processing participant 444...\n",
      "Normalized egemaps: shape (131038, 24)\n",
      "Normalized openface: shape (39317, 53)\n",
      "Created 3930 sequences for participant 444\n",
      "Processing participant 445...\n",
      "Normalized egemaps: shape (70947, 24)\n",
      "Normalized openface: shape (21290, 53)\n",
      "Created 2128 sequences for participant 445\n",
      "Processing participant 446...\n",
      "Normalized egemaps: shape (99820, 24)\n",
      "Normalized openface: shape (29955, 53)\n",
      "Created 2994 sequences for participant 446\n",
      "Saving intermediate results for train after batch 11\n",
      "Processing batch 12/17 in train set\n",
      "Processing participant 447...\n",
      "Normalized egemaps: shape (82017, 24)\n",
      "Normalized openface: shape (24610, 53)\n",
      "Created 2460 sequences for participant 447\n",
      "Processing participant 449...\n",
      "Normalized egemaps: shape (102954, 24)\n",
      "Normalized openface: shape (30893, 53)\n",
      "Created 3088 sequences for participant 449\n",
      "Processing participant 450...\n",
      "Normalized egemaps: shape (127504, 24)\n",
      "Normalized openface: shape (38256, 53)\n",
      "Created 3824 sequences for participant 450\n",
      "Processing participant 452...\n",
      "Normalized egemaps: shape (88885, 24)\n",
      "Normalized openface: shape (26673, 53)\n",
      "Created 2666 sequences for participant 452\n",
      "Processing participant 453...\n",
      "Normalized egemaps: shape (103197, 24)\n",
      "Normalized openface: shape (30969, 53)\n",
      "Created 3095 sequences for participant 453\n",
      "Processing participant 456...\n",
      "Normalized egemaps: shape (88260, 24)\n",
      "Normalized openface: shape (26485, 53)\n",
      "Created 2647 sequences for participant 456\n",
      "Processing participant 457...\n",
      "Normalized egemaps: shape (96215, 24)\n",
      "Normalized openface: shape (28871, 53)\n",
      "Created 2886 sequences for participant 457\n",
      "Processing participant 458...\n",
      "Normalized egemaps: shape (94965, 24)\n",
      "Normalized openface: shape (28494, 53)\n",
      "Created 2848 sequences for participant 458\n",
      "Processing participant 459...\n",
      "Normalized egemaps: shape (97487, 24)\n",
      "Normalized openface: shape (29254, 53)\n",
      "Created 2924 sequences for participant 459\n",
      "Processing participant 461...\n",
      "Normalized egemaps: shape (98139, 24)\n",
      "Normalized openface: shape (29446, 53)\n",
      "Created 2943 sequences for participant 461\n",
      "Saving intermediate results for train after batch 12\n",
      "Processing batch 13/17 in train set\n",
      "Processing participant 462...\n",
      "Normalized egemaps: shape (96498, 24)\n",
      "Normalized openface: shape (28952, 53)\n",
      "Created 2894 sequences for participant 462\n",
      "Processing participant 463...\n",
      "Normalized egemaps: shape (83466, 24)\n",
      "Normalized openface: shape (25039, 53)\n",
      "Created 2502 sequences for participant 463\n",
      "Processing participant 464...\n",
      "Normalized egemaps: shape (98016, 24)\n",
      "Normalized openface: shape (29410, 53)\n",
      "Created 2940 sequences for participant 464\n",
      "Processing participant 466...\n",
      "Normalized egemaps: shape (156639, 24)\n",
      "Normalized openface: shape (46997, 53)\n",
      "Created 4698 sequences for participant 466\n",
      "Processing participant 467...\n",
      "Normalized egemaps: shape (100226, 24)\n",
      "Normalized openface: shape (30074, 53)\n",
      "Created 3006 sequences for participant 467\n",
      "Processing participant 469...\n",
      "Normalized egemaps: shape (112650, 24)\n",
      "Normalized openface: shape (33799, 53)\n",
      "Created 3378 sequences for participant 469\n",
      "Processing participant 470...\n",
      "Normalized egemaps: shape (95527, 24)\n",
      "Normalized openface: shape (28662, 53)\n",
      "Created 2865 sequences for participant 470\n",
      "Processing participant 471...\n",
      "Normalized egemaps: shape (99518, 24)\n",
      "Normalized openface: shape (29862, 53)\n",
      "Created 2985 sequences for participant 471\n",
      "Processing participant 472...\n",
      "Normalized egemaps: shape (90296, 24)\n",
      "Normalized openface: shape (27092, 53)\n",
      "Created 2708 sequences for participant 472\n",
      "Processing participant 474...\n",
      "Normalized egemaps: shape (92724, 24)\n",
      "Normalized openface: shape (27822, 53)\n",
      "Created 2781 sequences for participant 474\n",
      "Saving intermediate results for train after batch 13\n",
      "Processing batch 14/17 in train set\n",
      "Processing participant 476...\n",
      "Normalized egemaps: shape (60861, 24)\n",
      "Normalized openface: shape (18265, 53)\n",
      "Created 1825 sequences for participant 476\n",
      "Processing participant 477...\n",
      "Normalized egemaps: shape (124450, 24)\n",
      "Normalized openface: shape (37341, 53)\n",
      "Created 3733 sequences for participant 477\n",
      "Processing participant 478...\n",
      "Normalized egemaps: shape (93602, 24)\n",
      "Normalized openface: shape (28087, 53)\n",
      "Created 2807 sequences for participant 478\n",
      "Processing participant 481...\n",
      "Normalized egemaps: shape (111619, 24)\n",
      "Normalized openface: shape (33491, 53)\n",
      "Created 3348 sequences for participant 481\n",
      "Processing participant 482...\n",
      "Normalized egemaps: shape (101876, 24)\n",
      "Normalized openface: shape (30570, 53)\n",
      "Created 3056 sequences for participant 482\n",
      "Processing participant 483...\n",
      "Normalized egemaps: shape (157685, 24)\n",
      "Normalized openface: shape (47313, 53)\n",
      "Created 4730 sequences for participant 483\n",
      "Processing participant 485...\n",
      "Normalized egemaps: shape (60252, 24)\n",
      "Normalized openface: shape (18082, 53)\n",
      "Created 1807 sequences for participant 485\n",
      "Processing participant 487...\n",
      "Normalized egemaps: shape (102335, 24)\n",
      "Normalized openface: shape (30710, 53)\n",
      "Created 3070 sequences for participant 487\n",
      "Processing participant 488...\n",
      "Normalized egemaps: shape (88478, 24)\n",
      "Normalized openface: shape (26549, 53)\n",
      "Created 2653 sequences for participant 488\n",
      "Processing participant 489...\n",
      "Normalized egemaps: shape (70448, 24)\n",
      "Normalized openface: shape (21141, 53)\n",
      "Created 2113 sequences for participant 489\n",
      "Saving intermediate results for train after batch 14\n",
      "Processing batch 15/17 in train set\n",
      "Processing participant 490...\n",
      "Normalized egemaps: shape (69113, 24)\n",
      "Normalized openface: shape (20740, 53)\n",
      "Created 2073 sequences for participant 490\n",
      "Processing participant 491...\n",
      "Normalized egemaps: shape (88150, 24)\n",
      "Normalized openface: shape (26451, 53)\n",
      "Created 2644 sequences for participant 491\n",
      "Processing participant 492...\n",
      "Normalized egemaps: shape (91233, 24)\n",
      "Normalized openface: shape (27375, 53)\n",
      "Created 2736 sequences for participant 492\n",
      "Processing participant 601...\n",
      "Normalized egemaps: shape (69950, 24)\n",
      "Normalized openface: shape (21157, 53)\n",
      "Created 2114 sequences for participant 601\n",
      "Processing participant 603...\n",
      "Normalized egemaps: shape (133714, 24)\n",
      "Normalized openface: shape (43445, 53)\n",
      "Created 4343 sequences for participant 603\n",
      "Processing participant 608...\n",
      "Normalized egemaps: shape (138408, 24)\n",
      "Normalized openface: shape (41540, 53)\n",
      "Created 4153 sequences for participant 608\n",
      "Processing participant 612...\n",
      "Normalized egemaps: shape (90725, 24)\n",
      "Normalized openface: shape (27219, 53)\n",
      "Created 2720 sequences for participant 612\n",
      "Processing participant 628...\n",
      "Normalized egemaps: shape (116482, 24)\n",
      "Normalized openface: shape (34946, 53)\n",
      "Created 3493 sequences for participant 628\n",
      "Processing participant 633...\n",
      "Normalized egemaps: shape (169205, 24)\n",
      "Normalized openface: shape (50760, 53)\n",
      "Created 5075 sequences for participant 633\n",
      "Processing participant 641...\n",
      "Normalized egemaps: shape (75481, 24)\n",
      "Normalized openface: shape (22649, 53)\n",
      "Created 2263 sequences for participant 641\n",
      "Saving intermediate results for train after batch 15\n",
      "Processing batch 16/17 in train set\n",
      "Processing participant 654...\n",
      "Normalized egemaps: shape (55619, 24)\n",
      "Normalized openface: shape (16692, 53)\n",
      "Created 1668 sequences for participant 654\n",
      "Processing participant 660...\n",
      "Normalized egemaps: shape (106917, 24)\n",
      "Normalized openface: shape (32080, 53)\n",
      "Created 3207 sequences for participant 660\n",
      "Processing participant 662...\n",
      "Normalized egemaps: shape (84710, 24)\n",
      "Normalized openface: shape (25416, 53)\n",
      "Created 2540 sequences for participant 662\n",
      "Processing participant 673...\n",
      "Normalized egemaps: shape (60178, 24)\n",
      "Normalized openface: shape (18057, 53)\n",
      "Created 1804 sequences for participant 673\n",
      "Processing participant 677...\n",
      "Normalized egemaps: shape (90029, 24)\n",
      "Normalized openface: shape (27012, 53)\n",
      "Created 2700 sequences for participant 677\n",
      "Processing participant 680...\n",
      "Normalized egemaps: shape (139088, 24)\n",
      "Normalized openface: shape (41733, 53)\n",
      "Created 4172 sequences for participant 680\n",
      "Processing participant 684...\n",
      "Normalized egemaps: shape (107320, 24)\n",
      "Normalized openface: shape (32202, 53)\n",
      "Created 3219 sequences for participant 684\n",
      "Processing participant 692...\n",
      "Normalized egemaps: shape (53901, 24)\n",
      "Normalized openface: shape (16175, 53)\n",
      "Created 1616 sequences for participant 692\n",
      "Processing participant 695...\n",
      "Normalized egemaps: shape (150662, 24)\n",
      "Normalized openface: shape (45204, 53)\n",
      "Created 4519 sequences for participant 695\n",
      "Processing participant 697...\n",
      "Normalized egemaps: shape (105824, 24)\n",
      "Normalized openface: shape (31754, 53)\n",
      "Created 3174 sequences for participant 697\n",
      "Saving intermediate results for train after batch 16\n",
      "Processing batch 17/17 in train set\n",
      "Processing participant 702...\n",
      "Normalized egemaps: shape (73274, 24)\n",
      "Normalized openface: shape (21988, 53)\n",
      "Created 2197 sequences for participant 702\n",
      "Processing participant 703...\n",
      "Normalized egemaps: shape (81278, 24)\n",
      "Normalized openface: shape (24391, 53)\n",
      "Created 2438 sequences for participant 703\n",
      "Processing participant 707...\n",
      "Normalized egemaps: shape (87031, 24)\n",
      "Normalized openface: shape (26110, 53)\n",
      "Created 2610 sequences for participant 707\n",
      "Saving intermediate results for train after batch 17\n",
      "Combining batch files for train...\n",
      "Found 17 batch files for train\n",
      "Processing batch file 1/17: train_batch_1.pkl\n",
      "Current progress: 28505 sequences, 7120 PTSD positive\n",
      "Processing batch file 2/17: train_batch_10.pkl\n",
      "Current progress: 56956 sequences, 12414 PTSD positive\n",
      "Processing batch file 3/17: train_batch_11.pkl\n",
      "Current progress: 89320 sequences, 16655 PTSD positive\n",
      "Processing batch file 4/17: train_batch_12.pkl\n",
      "Current progress: 118701 sequences, 26498 PTSD positive\n",
      "Processing batch file 5/17: train_batch_13.pkl\n",
      "Current progress: 149458 sequences, 31196 PTSD positive\n",
      "Processing batch file 6/17: train_batch_14.pkl\n",
      "Current progress: 178600 sequences, 38733 PTSD positive\n",
      "Processing batch file 7/17: train_batch_15.pkl\n",
      "Current progress: 210214 sequences, 48715 PTSD positive\n",
      "Processing batch file 8/17: train_batch_16.pkl\n",
      "Current progress: 238833 sequences, 64097 PTSD positive\n",
      "Processing batch file 9/17: train_batch_17.pkl\n",
      "Current progress: 246078 sequences, 64097 PTSD positive\n",
      "Processing batch file 10/17: train_batch_2.pkl\n",
      "Current progress: 272912 sequences, 66156 PTSD positive\n",
      "Processing batch file 11/17: train_batch_3.pkl\n",
      "Current progress: 300093 sequences, 78491 PTSD positive\n",
      "Processing batch file 12/17: train_batch_4.pkl\n",
      "Current progress: 325870 sequences, 91357 PTSD positive\n",
      "Processing batch file 13/17: train_batch_5.pkl\n",
      "Current progress: 347463 sequences, 102840 PTSD positive\n",
      "Processing batch file 14/17: train_batch_6.pkl\n",
      "Current progress: 385925 sequences, 119350 PTSD positive\n",
      "Processing batch file 15/17: train_batch_7.pkl\n",
      "Current progress: 418180 sequences, 132882 PTSD positive\n",
      "Processing batch file 16/17: train_batch_8.pkl\n",
      "Current progress: 445745 sequences, 142439 PTSD positive\n",
      "Processing batch file 17/17: train_batch_9.pkl\n",
      "Current progress: 476565 sequences, 151316 PTSD positive\n",
      "Combined train data saved with 476565 sequences\n",
      "PTSD positive: 151316/476565 (31.75%)\n",
      "Removed train_batch_1.pkl\n",
      "Removed train_batch_10.pkl\n",
      "Removed train_batch_11.pkl\n",
      "Removed train_batch_12.pkl\n",
      "Removed train_batch_13.pkl\n",
      "Removed train_batch_14.pkl\n",
      "Removed train_batch_15.pkl\n",
      "Removed train_batch_16.pkl\n",
      "Removed train_batch_17.pkl\n",
      "Removed train_batch_2.pkl\n",
      "Removed train_batch_3.pkl\n",
      "Removed train_batch_4.pkl\n",
      "Removed train_batch_5.pkl\n",
      "Removed train_batch_6.pkl\n",
      "Removed train_batch_7.pkl\n",
      "Removed train_batch_8.pkl\n",
      "Removed train_batch_9.pkl\n",
      "\n",
      "Processing dev set...\n",
      "Processing batch 1/6 in dev set\n",
      "Processing participant 300...\n",
      "Normalized egemaps: shape (64846, 24)\n",
      "Normalized openface: shape (19458, 53)\n",
      "Created 1944 sequences for participant 300\n",
      "Processing participant 301...\n",
      "Normalized egemaps: shape (82386, 24)\n",
      "Normalized openface: shape (24721, 53)\n",
      "Created 2471 sequences for participant 301\n",
      "Processing participant 306...\n",
      "Normalized egemaps: shape (85806, 24)\n",
      "Normalized openface: shape (25744, 53)\n",
      "Created 2573 sequences for participant 306\n",
      "Processing participant 317...\n",
      "Normalized egemaps: shape (80486, 24)\n",
      "Normalized openface: shape (24395, 53)\n",
      "Created 2438 sequences for participant 317\n",
      "Processing participant 320...\n",
      "Normalized egemaps: shape (84066, 24)\n",
      "Normalized openface: shape (25480, 53)\n",
      "Created 2547 sequences for participant 320\n",
      "Processing participant 321...\n",
      "Normalized egemaps: shape (82186, 24)\n",
      "Normalized openface: shape (24658, 53)\n",
      "Created 2464 sequences for participant 321\n",
      "Processing participant 331...\n",
      "Normalized egemaps: shape (85066, 24)\n",
      "Normalized openface: shape (25524, 53)\n",
      "Created 2551 sequences for participant 331\n",
      "Processing participant 334...\n",
      "Normalized egemaps: shape (97996, 24)\n",
      "Normalized openface: shape (29400, 53)\n",
      "Created 2939 sequences for participant 334\n",
      "Processing participant 336...\n",
      "Normalized egemaps: shape (94440, 24)\n",
      "Normalized openface: shape (28337, 53)\n",
      "Created 2832 sequences for participant 336\n",
      "Processing participant 343...\n",
      "Normalized egemaps: shape (92726, 24)\n",
      "Normalized openface: shape (27819, 53)\n",
      "Created 2780 sequences for participant 343\n",
      "Saving intermediate results for dev after batch 1\n",
      "Processing batch 2/6 in dev set\n",
      "Processing participant 344...\n",
      "Normalized egemaps: shape (109046, 24)\n",
      "Normalized openface: shape (32718, 53)\n",
      "Created 3270 sequences for participant 344\n",
      "Processing participant 347...\n",
      "Normalized egemaps: shape (61139, 24)\n",
      "Normalized openface: shape (18348, 53)\n",
      "Created 1833 sequences for participant 347\n",
      "Processing participant 350...\n",
      "Normalized egemaps: shape (88174, 24)\n",
      "Normalized openface: shape (26455, 53)\n",
      "Created 2644 sequences for participant 350\n",
      "Processing participant 365...\n",
      "Normalized egemaps: shape (138589, 24)\n",
      "Normalized openface: shape (41585, 53)\n",
      "Created 4157 sequences for participant 365\n",
      "Processing participant 371...\n",
      "Normalized egemaps: shape (91150, 24)\n",
      "Normalized openface: shape (27356, 53)\n",
      "Created 2734 sequences for participant 371\n",
      "Processing participant 373...\n",
      "Normalized egemaps: shape (126499, 24)\n",
      "Normalized openface: shape (37951, 53)\n",
      "Created 3794 sequences for participant 373\n",
      "Processing participant 374...\n",
      "Normalized egemaps: shape (128758, 24)\n",
      "Normalized openface: shape (38631, 53)\n",
      "Created 3862 sequences for participant 374\n",
      "Processing participant 381...\n",
      "Normalized egemaps: shape (108924, 24)\n",
      "Normalized openface: shape (32681, 53)\n",
      "Created 3267 sequences for participant 381\n",
      "Processing participant 382...\n",
      "Normalized egemaps: shape (82397, 24)\n",
      "Normalized openface: shape (24728, 53)\n",
      "Created 2471 sequences for participant 382\n",
      "Processing participant 388...\n",
      "Normalized egemaps: shape (83112, 24)\n",
      "Normalized openface: shape (24935, 53)\n",
      "Created 2492 sequences for participant 388\n",
      "Saving intermediate results for dev after batch 2\n",
      "Processing batch 3/6 in dev set\n",
      "Processing participant 393...\n",
      "Normalized egemaps: shape (62992, 24)\n",
      "Normalized openface: shape (18904, 53)\n",
      "Created 1889 sequences for participant 393\n",
      "Processing participant 401...\n",
      "Normalized egemaps: shape (93399, 24)\n",
      "Normalized openface: shape (28027, 53)\n",
      "Created 2801 sequences for participant 401\n",
      "Processing participant 402...\n",
      "Normalized egemaps: shape (95545, 24)\n",
      "Normalized openface: shape (24999, 53)\n",
      "Created 2498 sequences for participant 402\n",
      "Processing participant 408...\n",
      "Normalized egemaps: shape (71578, 24)\n",
      "Normalized openface: shape (21477, 53)\n",
      "Created 2146 sequences for participant 408\n",
      "Processing participant 412...\n",
      "Normalized egemaps: shape (85676, 24)\n",
      "Normalized openface: shape (25709, 53)\n",
      "Created 2569 sequences for participant 412\n",
      "Processing participant 415...\n",
      "Normalized egemaps: shape (78054, 24)\n",
      "Normalized openface: shape (23423, 53)\n",
      "Created 2341 sequences for participant 415\n",
      "Processing participant 423...\n",
      "Normalized egemaps: shape (99565, 24)\n",
      "Normalized openface: shape (29878, 53)\n",
      "Created 2986 sequences for participant 423\n",
      "Processing participant 425...\n",
      "Normalized egemaps: shape (115475, 24)\n",
      "Normalized openface: shape (34644, 53)\n",
      "Created 3463 sequences for participant 425\n",
      "Processing participant 431...\n",
      "Normalized egemaps: shape (83357, 24)\n",
      "Normalized openface: shape (25019, 53)\n",
      "Created 2500 sequences for participant 431\n",
      "Processing participant 433...\n",
      "Normalized egemaps: shape (80171, 24)\n",
      "Normalized openface: shape (24055, 53)\n",
      "Created 2404 sequences for participant 433\n",
      "Saving intermediate results for dev after batch 3\n",
      "Processing batch 4/6 in dev set\n",
      "Processing participant 435...\n",
      "Normalized egemaps: shape (118496, 24)\n",
      "Normalized openface: shape (35550, 53)\n",
      "Created 3554 sequences for participant 435\n",
      "Processing participant 437...\n",
      "Normalized egemaps: shape (84941, 24)\n",
      "Normalized openface: shape (25487, 53)\n",
      "Created 2547 sequences for participant 437\n",
      "Processing participant 441...\n",
      "Normalized egemaps: shape (97116, 24)\n",
      "Normalized openface: shape (29141, 53)\n",
      "Created 2913 sequences for participant 441\n",
      "Processing participant 442...\n",
      "Normalized egemaps: shape (94987, 24)\n",
      "Normalized openface: shape (28502, 53)\n",
      "Created 2849 sequences for participant 442\n",
      "Processing participant 448...\n",
      "Normalized egemaps: shape (121287, 24)\n",
      "Normalized openface: shape (36390, 53)\n",
      "Created 3638 sequences for participant 448\n",
      "Processing participant 451...\n",
      "Normalized egemaps: shape (118819, 24)\n",
      "Normalized openface: shape (35654, 53)\n",
      "Created 3564 sequences for participant 451\n",
      "Processing participant 454...\n",
      "Normalized egemaps: shape (80396, 24)\n",
      "Normalized openface: shape (24126, 53)\n",
      "Created 2411 sequences for participant 454\n",
      "Processing participant 455...\n",
      "Normalized egemaps: shape (75018, 24)\n",
      "Normalized openface: shape (22511, 53)\n",
      "Created 2250 sequences for participant 455\n",
      "Processing participant 465...\n",
      "Normalized egemaps: shape (116318, 24)\n",
      "Normalized openface: shape (34905, 53)\n",
      "Created 3489 sequences for participant 465\n",
      "Processing participant 468...\n",
      "Normalized egemaps: shape (93956, 24)\n",
      "Normalized openface: shape (28193, 53)\n",
      "Created 2818 sequences for participant 468\n",
      "Saving intermediate results for dev after batch 4\n",
      "Processing batch 5/6 in dev set\n",
      "Processing participant 473...\n",
      "Normalized egemaps: shape (53307, 24)\n",
      "Normalized openface: shape (16000, 53)\n",
      "Created 1599 sequences for participant 473\n",
      "Processing participant 475...\n",
      "Normalized egemaps: shape (58714, 24)\n",
      "Normalized openface: shape (17617, 53)\n",
      "Created 1760 sequences for participant 475\n",
      "Processing participant 479...\n",
      "Normalized egemaps: shape (91027, 24)\n",
      "Normalized openface: shape (27311, 53)\n",
      "Created 2730 sequences for participant 479\n",
      "Processing participant 480...\n",
      "Normalized egemaps: shape (86561, 24)\n",
      "Normalized openface: shape (25970, 53)\n",
      "Created 2596 sequences for participant 480\n",
      "Processing participant 484...\n",
      "Normalized egemaps: shape (99528, 24)\n",
      "Normalized openface: shape (29864, 53)\n",
      "Created 2985 sequences for participant 484\n",
      "Processing participant 486...\n",
      "Normalized egemaps: shape (68212, 24)\n",
      "Normalized openface: shape (20472, 53)\n",
      "Created 2046 sequences for participant 486\n",
      "Processing participant 617...\n",
      "Normalized egemaps: shape (136399, 24)\n",
      "Normalized openface: shape (40921, 53)\n",
      "Created 4091 sequences for participant 617\n",
      "Processing participant 627...\n",
      "Normalized egemaps: shape (362761, 24)\n",
      "Normalized openface: shape (108830, 53)\n",
      "Created 10882 sequences for participant 627\n",
      "Processing participant 632...\n",
      "Normalized egemaps: shape (119665, 24)\n",
      "Normalized openface: shape (35901, 53)\n",
      "Created 3589 sequences for participant 632\n",
      "Processing participant 653...\n",
      "Normalized egemaps: shape (66471, 24)\n",
      "Normalized openface: shape (19947, 53)\n",
      "Created 1993 sequences for participant 653\n",
      "Saving intermediate results for dev after batch 5\n",
      "Processing batch 6/6 in dev set\n",
      "Processing participant 657...\n",
      "Normalized egemaps: shape (96661, 24)\n",
      "Normalized openface: shape (29005, 53)\n",
      "Created 2899 sequences for participant 657\n",
      "Processing participant 667...\n",
      "Normalized egemaps: shape (86330, 24)\n",
      "Normalized openface: shape (25905, 53)\n",
      "Created 2589 sequences for participant 667\n",
      "Processing participant 670...\n",
      "Normalized egemaps: shape (63815, 24)\n",
      "Normalized openface: shape (19150, 53)\n",
      "Created 1914 sequences for participant 670\n",
      "Processing participant 687...\n",
      "Normalized egemaps: shape (111216, 24)\n",
      "Normalized openface: shape (33368, 53)\n",
      "Created 3335 sequences for participant 687\n",
      "Processing participant 698...\n",
      "Normalized egemaps: shape (144534, 24)\n",
      "Normalized openface: shape (43364, 53)\n",
      "Created 4335 sequences for participant 698\n",
      "Processing participant 713...\n",
      "Normalized egemaps: shape (79026, 24)\n",
      "Normalized openface: shape (23710, 53)\n",
      "Created 2370 sequences for participant 713\n",
      "Saving intermediate results for dev after batch 6\n",
      "Combining batch files for dev...\n",
      "Found 6 batch files for dev\n",
      "Processing batch file 1/6: dev_batch_1.pkl\n",
      "Current progress: 25539 sequences, 10000 PTSD positive\n",
      "Processing batch file 2/6: dev_batch_2.pkl\n",
      "Current progress: 56063 sequences, 24920 PTSD positive\n",
      "Processing batch file 3/6: dev_batch_3.pkl\n",
      "Current progress: 81660 sequences, 30219 PTSD positive\n",
      "Processing batch file 4/6: dev_batch_4.pkl\n",
      "Current progress: 111693 sequences, 40324 PTSD positive\n",
      "Processing batch file 5/6: dev_batch_5.pkl\n",
      "Current progress: 145964 sequences, 44415 PTSD positive\n",
      "Processing batch file 6/6: dev_batch_6.pkl\n",
      "Current progress: 163406 sequences, 52085 PTSD positive\n",
      "Combined dev data saved with 163406 sequences\n",
      "PTSD positive: 52085/163406 (31.87%)\n",
      "Removed dev_batch_1.pkl\n",
      "Removed dev_batch_2.pkl\n",
      "Removed dev_batch_3.pkl\n",
      "Removed dev_batch_4.pkl\n",
      "Removed dev_batch_5.pkl\n",
      "Removed dev_batch_6.pkl\n",
      "\n",
      "Processing test set...\n",
      "Processing batch 1/6 in test set\n",
      "Processing participant 600...\n",
      "Normalized egemaps: shape (68575, 24)\n",
      "Normalized openface: shape (20579, 53)\n",
      "Created 2056 sequences for participant 600\n",
      "Processing participant 602...\n",
      "Normalized egemaps: shape (77785, 24)\n",
      "Normalized openface: shape (25550, 53)\n",
      "Created 2554 sequences for participant 602\n",
      "Processing participant 604...\n",
      "Normalized egemaps: shape (62677, 24)\n",
      "Normalized openface: shape (18832, 53)\n",
      "Created 1882 sequences for participant 604\n",
      "Processing participant 605...\n",
      "Normalized egemaps: shape (80854, 24)\n",
      "Normalized openface: shape (24269, 53)\n",
      "Created 2425 sequences for participant 605\n",
      "Processing participant 606...\n",
      "Normalized egemaps: shape (52915, 24)\n",
      "Normalized openface: shape (15880, 53)\n",
      "Created 1587 sequences for participant 606\n",
      "Processing participant 607...\n",
      "Normalized egemaps: shape (79197, 24)\n",
      "Normalized openface: shape (23773, 53)\n",
      "Created 2376 sequences for participant 607\n",
      "Processing participant 609...\n",
      "Normalized egemaps: shape (134102, 24)\n",
      "Normalized openface: shape (34818, 53)\n",
      "Created 3480 sequences for participant 609\n",
      "Processing participant 615...\n",
      "Normalized egemaps: shape (122621, 24)\n",
      "Normalized openface: shape (36787, 53)\n",
      "Created 3677 sequences for participant 615\n",
      "Processing participant 618...\n",
      "Normalized egemaps: shape (89065, 24)\n",
      "Normalized openface: shape (26721, 53)\n",
      "Created 2671 sequences for participant 618\n",
      "Processing participant 619...\n",
      "Normalized egemaps: shape (116858, 24)\n",
      "Normalized openface: shape (35059, 53)\n",
      "Created 3504 sequences for participant 619\n",
      "Saving intermediate results for test after batch 1\n",
      "Processing batch 2/6 in test set\n",
      "Processing participant 620...\n",
      "Normalized egemaps: shape (115820, 24)\n",
      "Normalized openface: shape (34747, 53)\n",
      "Created 3473 sequences for participant 620\n",
      "Processing participant 622...\n",
      "Normalized egemaps: shape (82912, 24)\n",
      "Normalized openface: shape (24875, 53)\n",
      "Created 2486 sequences for participant 622\n",
      "Processing participant 623...\n",
      "Normalized egemaps: shape (150802, 24)\n",
      "Normalized openface: shape (45242, 53)\n",
      "Created 4523 sequences for participant 623\n",
      "Processing participant 624...\n",
      "Normalized egemaps: shape (84932, 24)\n",
      "Normalized openface: shape (25481, 53)\n",
      "Created 2547 sequences for participant 624\n",
      "Processing participant 625...\n",
      "Normalized egemaps: shape (115638, 24)\n",
      "Normalized openface: shape (34693, 53)\n",
      "Created 3468 sequences for participant 625\n",
      "Processing participant 626...\n",
      "Normalized egemaps: shape (61112, 24)\n",
      "Normalized openface: shape (18335, 53)\n",
      "Created 1832 sequences for participant 626\n",
      "Processing participant 629...\n",
      "Normalized egemaps: shape (139708, 24)\n",
      "Normalized openface: shape (41914, 53)\n",
      "Created 4190 sequences for participant 629\n",
      "Processing participant 631...\n",
      "Normalized egemaps: shape (61898, 24)\n",
      "Normalized openface: shape (18571, 53)\n",
      "Created 1856 sequences for participant 631\n",
      "Processing participant 634...\n",
      "Normalized egemaps: shape (81762, 24)\n",
      "Normalized openface: shape (24524, 53)\n",
      "Created 2451 sequences for participant 634\n",
      "Processing participant 635...\n",
      "Normalized egemaps: shape (53124, 24)\n",
      "Normalized openface: shape (15925, 53)\n",
      "Created 1591 sequences for participant 635\n",
      "Saving intermediate results for test after batch 2\n",
      "Processing batch 3/6 in test set\n",
      "Processing participant 636...\n",
      "Normalized egemaps: shape (168679, 24)\n",
      "Normalized openface: shape (50605, 53)\n",
      "Created 5059 sequences for participant 636\n",
      "Processing participant 637...\n",
      "Normalized egemaps: shape (124523, 24)\n",
      "Normalized openface: shape (37358, 53)\n",
      "Created 3734 sequences for participant 637\n",
      "Processing participant 638...\n",
      "Normalized egemaps: shape (52504, 24)\n",
      "Normalized openface: shape (15752, 53)\n",
      "Created 1574 sequences for participant 638\n",
      "Processing participant 640...\n",
      "Normalized egemaps: shape (81336, 24)\n",
      "Normalized openface: shape (24406, 53)\n",
      "Created 2439 sequences for participant 640\n",
      "Processing participant 649...\n",
      "Normalized egemaps: shape (99181, 24)\n",
      "Normalized openface: shape (29761, 53)\n",
      "Created 2975 sequences for participant 649\n",
      "Processing participant 650...\n",
      "Normalized egemaps: shape (103565, 24)\n",
      "Normalized openface: shape (31071, 53)\n",
      "Created 3106 sequences for participant 650\n",
      "Processing participant 651...\n",
      "Normalized egemaps: shape (58651, 24)\n",
      "Normalized openface: shape (17600, 53)\n",
      "Created 1759 sequences for participant 651\n",
      "Processing participant 652...\n",
      "Normalized egemaps: shape (95320, 24)\n",
      "Normalized openface: shape (28599, 53)\n",
      "Created 2858 sequences for participant 652\n",
      "Processing participant 655...\n",
      "Normalized egemaps: shape (85491, 24)\n",
      "Normalized openface: shape (25653, 53)\n",
      "Created 2564 sequences for participant 655\n",
      "Processing participant 656...\n",
      "Normalized egemaps: shape (76363, 24)\n",
      "Normalized openface: shape (22912, 53)\n",
      "Created 2290 sequences for participant 656\n",
      "Saving intermediate results for test after batch 3\n",
      "Processing batch 4/6 in test set\n",
      "Processing participant 658...\n",
      "Normalized egemaps: shape (98806, 24)\n",
      "Normalized openface: shape (29646, 53)\n",
      "Created 2963 sequences for participant 658\n",
      "Processing participant 659...\n",
      "Normalized egemaps: shape (127850, 24)\n",
      "Normalized openface: shape (38357, 53)\n",
      "Created 3834 sequences for participant 659\n",
      "Processing participant 661...\n",
      "Normalized egemaps: shape (125361, 24)\n",
      "Normalized openface: shape (37609, 53)\n",
      "Created 3759 sequences for participant 661\n",
      "Processing participant 663...\n",
      "Normalized egemaps: shape (89443, 24)\n",
      "Normalized openface: shape (26839, 53)\n",
      "Created 2682 sequences for participant 663\n",
      "Processing participant 664...\n",
      "Normalized egemaps: shape (119830, 24)\n",
      "Normalized openface: shape (35950, 53)\n",
      "Created 3594 sequences for participant 664\n",
      "Processing participant 666...\n",
      "Normalized egemaps: shape (120530, 24)\n",
      "Normalized openface: shape (36163, 53)\n",
      "Created 3615 sequences for participant 666\n",
      "Processing participant 669...\n",
      "Normalized egemaps: shape (140888, 24)\n",
      "Normalized openface: shape (42273, 53)\n",
      "Created 4226 sequences for participant 669\n",
      "Processing participant 676...\n",
      "Normalized egemaps: shape (58323, 24)\n",
      "Normalized openface: shape (17500, 53)\n",
      "Created 1749 sequences for participant 676\n",
      "Processing participant 679...\n",
      "Normalized egemaps: shape (123846, 24)\n",
      "Normalized openface: shape (37161, 53)\n",
      "Created 3715 sequences for participant 679\n",
      "Processing participant 682...\n",
      "Normalized egemaps: shape (73473, 24)\n",
      "Normalized openface: shape (22048, 53)\n",
      "Created 2203 sequences for participant 682\n",
      "Saving intermediate results for test after batch 4\n",
      "Processing batch 5/6 in test set\n",
      "Processing participant 683...\n",
      "Normalized egemaps: shape (128363, 24)\n",
      "Normalized openface: shape (38516, 53)\n",
      "Created 3850 sequences for participant 683\n",
      "Processing participant 688...\n",
      "Normalized egemaps: shape (112681, 24)\n",
      "Normalized openface: shape (33811, 53)\n",
      "Created 3380 sequences for participant 688\n",
      "Processing participant 689...\n",
      "Normalized egemaps: shape (89001, 24)\n",
      "Normalized openface: shape (26702, 53)\n",
      "Created 2669 sequences for participant 689\n",
      "Processing participant 691...\n",
      "Normalized egemaps: shape (129784, 24)\n",
      "Normalized openface: shape (38940, 53)\n",
      "Created 3893 sequences for participant 691\n",
      "Processing participant 693...\n",
      "Normalized egemaps: shape (69159, 24)\n",
      "Normalized openface: shape (20752, 53)\n",
      "Created 2074 sequences for participant 693\n",
      "Processing participant 696...\n",
      "Normalized egemaps: shape (76337, 24)\n",
      "Normalized openface: shape (22907, 53)\n",
      "Created 2289 sequences for participant 696\n",
      "Processing participant 699...\n",
      "Normalized egemaps: shape (73271, 24)\n",
      "Normalized openface: shape (21987, 53)\n",
      "Created 2197 sequences for participant 699\n",
      "Processing participant 705...\n",
      "Normalized egemaps: shape (78586, 24)\n",
      "Normalized openface: shape (23580, 53)\n",
      "Created 2357 sequences for participant 705\n",
      "Processing participant 708...\n",
      "Normalized egemaps: shape (89588, 24)\n",
      "Normalized openface: shape (26882, 53)\n",
      "Created 2687 sequences for participant 708\n",
      "Processing participant 709...\n",
      "Normalized egemaps: shape (81971, 24)\n",
      "Normalized openface: shape (24592, 53)\n",
      "Created 2458 sequences for participant 709\n",
      "Saving intermediate results for test after batch 5\n",
      "Processing batch 6/6 in test set\n",
      "Processing participant 710...\n",
      "Normalized egemaps: shape (83304, 24)\n",
      "Normalized openface: shape (24998, 53)\n",
      "Created 2498 sequences for participant 710\n",
      "Processing participant 712...\n",
      "Normalized egemaps: shape (122579, 24)\n",
      "Normalized openface: shape (36781, 53)\n",
      "Created 3677 sequences for participant 712\n",
      "Processing participant 715...\n",
      "Normalized egemaps: shape (130325, 24)\n",
      "Normalized openface: shape (39099, 53)\n",
      "Created 3908 sequences for participant 715\n",
      "Processing participant 716...\n",
      "Normalized egemaps: shape (96965, 24)\n",
      "Normalized openface: shape (29091, 53)\n",
      "Created 2908 sequences for participant 716\n",
      "Processing participant 717...\n",
      "Normalized egemaps: shape (97936, 24)\n",
      "Normalized openface: shape (29387, 53)\n",
      "Created 2937 sequences for participant 717\n",
      "Processing participant 718...\n",
      "Normalized egemaps: shape (128170, 24)\n",
      "Normalized openface: shape (38456, 53)\n",
      "Created 3844 sequences for participant 718\n",
      "Saving intermediate results for test after batch 6\n",
      "Combining batch files for test...\n",
      "Found 6 batch files for test\n",
      "Processing batch file 1/6: test_batch_1.pkl\n",
      "Current progress: 26212 sequences, 2554 PTSD positive\n",
      "Processing batch file 2/6: test_batch_2.pkl\n",
      "Current progress: 54629 sequences, 5101 PTSD positive\n",
      "Processing batch file 3/6: test_batch_3.pkl\n",
      "Current progress: 82987 sequences, 20131 PTSD positive\n",
      "Processing batch file 4/6: test_batch_4.pkl\n",
      "Current progress: 115327 sequences, 41310 PTSD positive\n",
      "Processing batch file 5/6: test_batch_5.pkl\n",
      "Current progress: 143181 sequences, 58095 PTSD positive\n",
      "Processing batch file 6/6: test_batch_6.pkl\n",
      "Current progress: 162953 sequences, 63501 PTSD positive\n",
      "Combined test data saved with 162953 sequences\n",
      "PTSD positive: 63501/162953 (38.97%)\n",
      "Removed test_batch_1.pkl\n",
      "Removed test_batch_2.pkl\n",
      "Removed test_batch_3.pkl\n",
      "Removed test_batch_4.pkl\n",
      "Removed test_batch_5.pkl\n",
      "Removed test_batch_6.pkl\n",
      "\n",
      "Dataset processing complete!\n",
      "\n",
      "Dataset Statistics:\n",
      "train data file not found\n",
      "dev data file not found\n",
      "test data file not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the batch processing\n",
    "process_full_dataset_batched(BASE_PATH, LABELS_PATH, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0cdd638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T20:40:13.763329Z",
     "iopub.status.busy": "2025-05-02T20:40:13.763107Z",
     "iopub.status.idle": "2025-05-02T20:40:13.767345Z",
     "shell.execute_reply": "2025-05-02T20:40:13.766913Z",
     "shell.execute_reply.started": "2025-05-02T20:40:13.763314Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_with_gpu_memory_constraints(train_audio, train_visual, train_labels, dev_audio, dev_visual, dev_labels, batch_size=32):\n",
    "    \"\"\"\n",
    "    Process data in smaller batches to avoid GPU memory issues\n",
    "    \n",
    "    Args:\n",
    "        train_audio: Training audio features\n",
    "        train_visual: Training visual features\n",
    "        train_labels: Training labels\n",
    "        dev_audio: Validation audio features\n",
    "        dev_visual: Validation visual features\n",
    "        dev_labels: Validation labels\n",
    "        batch_size: Batch size for training\n",
    "    \n",
    "    Returns:\n",
    "        model_inputs: Dictionary with all necessary data for model training\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Processing data with GPU memory constraints...\")\n",
    "    \n",
    "    # 1. Use CPU for initial tensor conversions\n",
    "    with tf.device('/CPU:0'):\n",
    "        # Make sure labels match the size of features\n",
    "        num_train_samples = min(len(train_audio), len(train_visual))\n",
    "        train_labels_subset = train_labels[:num_train_samples]\n",
    "        \n",
    "        num_dev_samples = min(len(dev_audio), len(dev_visual))\n",
    "        dev_labels_subset = dev_labels[:num_dev_samples]\n",
    "        \n",
    "        # Create sample weights for class imbalance\n",
    "        from sklearn.utils import class_weight\n",
    "        classes = np.unique(train_labels_subset)\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=classes,\n",
    "            y=train_labels_subset\n",
    "        )\n",
    "        class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "        \n",
    "        # Create dataset objects to handle memory efficiently\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ((train_audio[:num_train_samples], train_visual[:num_train_samples]), \n",
    "             train_labels_subset)\n",
    "        ).batch(batch_size)\n",
    "        \n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ((dev_audio[:num_dev_samples], dev_visual[:num_dev_samples]), \n",
    "             dev_labels_subset)\n",
    "        ).batch(batch_size)\n",
    "    \n",
    "    # 2. Return the TensorFlow datasets and related info\n",
    "    return {\n",
    "        'train_dataset': train_dataset,\n",
    "        'val_dataset': val_dataset,\n",
    "        'class_weight_dict': class_weight_dict,\n",
    "        'train_samples': num_train_samples,\n",
    "        'val_samples': num_dev_samples,\n",
    "        'batch_size': batch_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa138616",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "Once the preprocessing is complete with this memory-optimized approach, we can move on to model development:\n",
    "\n",
    "1. Build a two-branch LSTM architecture with cross-modal attention\n",
    "2. Implement class balancing to handle imbalanced data\n",
    "3. Train the model with proper validation\n",
    "4. Evaluate on test set and compare with baselines\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
